{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Necessities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mahadik/miniconda3/envs/fairgnn_env/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Imports\n",
    "# ------------------------------------------------------------------\n",
    "# Basic data processing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Graph data processing libraries\n",
    "import networkx as nx\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import from_networkx\n",
    "\n",
    "# Libraries for (G)NNs\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Helper functions\n",
    "# ------------------------------------------------------------------\n",
    "def show_df_info(df):\n",
    "    print(df.info())\n",
    "    print('####### Repeat ####### \\n', df.duplicated().any())\n",
    "    print('####### Count ####### \\n', df.nunique())\n",
    "    print('####### Example ####### \\n',df.head())\n",
    "\n",
    "def label_statics(label_df, label_list):\n",
    "    print(\"####### nCount #######\")\n",
    "    for label in label_list:\n",
    "        print(label_df[label].value_counts())\n",
    "    print(\"####### nPercent #######\")\n",
    "    for label in label_list:\n",
    "        print(label_df[label].value_counts()/label_df.shape[0])\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Data stuff\n",
    "# ------------------------------------------------------------------\n",
    "base_path = os.getcwd()\n",
    "input_ali_data_path = os.path.join(base_path, \"input_ali_data\")\n",
    "\n",
    "# Load the data files\n",
    "user_labels_path = os.path.join(input_ali_data_path, \"user_labels.csv\")\n",
    "user_edges_path = os.path.join(input_ali_data_path, \"user_edge.csv\")\n",
    "\n",
    "# Create dataframes to store the information from the .csv files\n",
    "user_labels = pd.read_csv(user_labels_path)\n",
    "user_edges = pd.read_csv(user_edges_path)\n",
    "\n",
    "# Prepare the data for GNNs\n",
    "node_features = torch.tensor(user_labels.iloc[:, 1:].values, dtype=torch.float)\n",
    "edge_index = torch.tensor(user_edges.values, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# Create torch-geometric data\n",
    "data = Data(x=node_features, edge_index=edge_index)\n",
    "\n",
    "num_nodes = node_features.size(0)\n",
    "num_classes = 2 \n",
    "num_node_features = data.num_node_features\n",
    "\n",
    "# Create masks for training, and testing\n",
    "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "\n",
    "# 60-20-20 Train and Test data split\n",
    "num_train = int(num_nodes * 0.6)\n",
    "num_val = int(num_nodes * 0.8)\n",
    "train_mask[:num_train] = True\n",
    "val_mask[num_train:num_val] = True\n",
    "test_mask[num_val:] = True\n",
    "\n",
    "data.train_mask = train_mask\n",
    "data.test_mask = test_mask\n",
    "data.val_mask = val_mask\n",
    "\n",
    "# Labels from the data (in this case: Job Classification)\n",
    "data.y = torch.tensor(user_labels['gender'].values, dtype=torch.long)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Set Device\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "def set_device():\n",
    "    return torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Loss\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "def fairness_aware_loss(output, data, sensitive_attr, alpha=0, beta=0, gamma=0, delta=0):\n",
    "    target = data.y[data.train_mask]\n",
    "    # standard_loss = F.cross_entropy(output, target)\n",
    "    standard_loss = F.nll_loss(output, target)\n",
    "\n",
    "    labels = data.y[train_mask]\n",
    "    pos_prob = torch.exp(output[:, 1])\n",
    "    neg_prob = torch.exp(output[:, 0])\n",
    "    # pos_prob = torch.sigmoid(output[:, 1])\n",
    "    # neg_prob = 1 - pos_prob\n",
    "    predictions = output.argmax(dim=1)\n",
    "\n",
    "    # Statistical Parity Regularization\n",
    "    sp_reg = torch.abs(pos_prob[sensitive_attr == 1].mean() - pos_prob[sensitive_attr == 0].mean())\n",
    "\n",
    "    # # Calculating FPR and TPR for each group\n",
    "    # fpr_group1 = ((predictions == 1) & (labels == 0) & (sensitive_attr == 1)).float().mean()\n",
    "    # fpr_group0 = ((predictions == 1) & (labels == 0) & (sensitive_attr == 0)).float().mean()\n",
    "    # tpr_group1 = ((predictions == 1) & (labels == 1) & (sensitive_attr == 1)).float().mean()\n",
    "    # tpr_group0 = ((predictions == 1) & (labels == 1) & (sensitive_attr == 0)).float().mean()\n",
    "\n",
    "    # Treatment Equality Regularization\n",
    "    fp_diff = (neg_prob * (labels == 0) * (sensitive_attr == 1)).float().mean() - \\\n",
    "              (neg_prob * (labels == 0) * (sensitive_attr == 0)).float().mean()\n",
    "    fn_diff = (pos_prob * (labels == 1) * (sensitive_attr == 1)).float().mean() - \\\n",
    "              (pos_prob * (labels == 1) * (sensitive_attr == 0)).float().mean()\n",
    "    treatment_reg = torch.abs(fp_diff) + torch.abs(fn_diff)\n",
    "    # treatment_reg = torch.abs(fn_diff)\n",
    "\n",
    "    # fn_group_1 = ((predictions == 0) & (labels == 1) & (sensitive_attr == 1)).sum()\n",
    "    # fp_group_1 = ((predictions == 1) & (labels == 0) & (sensitive_attr == 1)).sum()\n",
    "\n",
    "    # fn_group_0 = ((predictions == 0) & (labels == 1) & (sensitive_attr == 0)).sum()\n",
    "    # fp_group_0 = ((predictions == 1) & (labels == 0) & (sensitive_attr == 0)).sum()\n",
    "    \n",
    "    # ratio_group_1 = fn_group_1 / fp_group_1 if fp_group_1 != 0 else torch.tensor(float('inf'))\n",
    "    # ratio_group_0 = fn_group_0 / fp_group_0 if fp_group_0 != 0 else torch.tensor(float('inf'))\n",
    "    # treatment_reg = torch.abs(ratio_group_1 - ratio_group_0)\n",
    "\n",
    "    # Equal Opportunity Difference Regularization\n",
    "    eod_reg = torch.abs((pos_prob * (labels == 1) * (sensitive_attr == 1)).float().mean() - \\\n",
    "                        (pos_prob * (labels == 1) * (sensitive_attr == 0)).float().mean())\n",
    "\n",
    "    # Overall Accuracy Equality Difference Regularization\n",
    "    oaed_reg = torch.abs((pos_prob * (sensitive_attr == 1)).float().mean() - \\\n",
    "                         (pos_prob * (sensitive_attr == 0)).float().mean())\n",
    "\n",
    "    penalty = alpha + beta + gamma + delta\n",
    "    \n",
    "    # Combine losses\n",
    "    combined_loss = (1-penalty)*standard_loss\n",
    "    + alpha * sp_reg\n",
    "    + beta * treatment_reg\n",
    "    + gamma * eod_reg\n",
    "    + delta * oaed_reg\n",
    "    \n",
    "    return combined_loss\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Fairness Metrics\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "def calculate_fairness(label, predictions, sens_attr='Gender', balanced=False):\n",
    "    \"\"\"\n",
    "    Calculate various fairness metrics.\n",
    "\n",
    "    Args:\n",
    "    label: Actual labels (binary).\n",
    "    predictions: Model predictions (binary).\n",
    "    sens_attr: Binary sensitive attribute for fairness evaluation.\n",
    "\n",
    "    Returns:\n",
    "    A dictionary containing SPD, EOD, OAED, and TED values.\n",
    "    \"\"\"\n",
    "    if balanced is False:\n",
    "        labels = torch.tensor(user_labels[label].values, dtype=torch.long)\n",
    "        sensitive_attribute = torch.tensor(user_labels[sens_attr].values, dtype=torch.long)\n",
    "    else:\n",
    "        labels = torch.tensor(filtered_user_labels[label].values, dtype=torch.long)\n",
    "        sensitive_attribute = torch.tensor(filtered_user_labels[sens_attr].values, dtype=torch.long)\n",
    "    \n",
    "    labels = labels.to(set_device())\n",
    "    sensitive_attribute = sensitive_attribute.to(set_device())\n",
    "\n",
    "    predictions = predictions.float()\n",
    "    labels = labels.float()\n",
    "    sensitive_attribute = sensitive_attribute.float()\n",
    "\n",
    "    def statistical_parity_difference():\n",
    "        prob_group_1 = predictions[sensitive_attribute == 1].mean()\n",
    "        prob_group_0 = predictions[sensitive_attribute == 0].mean()\n",
    "        return abs(prob_group_1 - prob_group_0), prob_group_0, prob_group_1\n",
    "\n",
    "    def equal_opportunity_difference():\n",
    "        tpr_group_1 = predictions[(labels == 1) & (sensitive_attribute == 1)].mean()\n",
    "        tpr_group_0 = predictions[(labels == 1) & (sensitive_attribute == 0)].mean()\n",
    "        return abs(tpr_group_1 - tpr_group_0), tpr_group_0, tpr_group_1\n",
    "\n",
    "    def overall_accuracy_equality_difference():\n",
    "        acc_group_1 = (predictions[sensitive_attribute == 1] == labels[sensitive_attribute == 1]).float().mean()\n",
    "        acc_group_0 = (predictions[sensitive_attribute == 0] == labels[sensitive_attribute == 0]).float().mean()\n",
    "        return abs(acc_group_1 - acc_group_0), acc_group_0, acc_group_1\n",
    "\n",
    "    def treatment_equality_difference():\n",
    "        fn_group_1 = ((predictions == 0) & (labels == 1) & (sensitive_attribute == 1)).sum()\n",
    "        fp_group_1 = ((predictions == 1) & (labels == 0) & (sensitive_attribute == 1)).sum()\n",
    "\n",
    "        fn_group_0 = ((predictions == 0) & (labels == 1) & (sensitive_attribute == 0)).sum()\n",
    "        fp_group_0 = ((predictions == 1) & (labels == 0) & (sensitive_attribute == 0)).sum()\n",
    "\n",
    "        ratio_group_1 = fn_group_1 / fp_group_1 if fp_group_1 != 0 else float('inf')\n",
    "        ratio_group_0 = fn_group_0 / fp_group_0 if fp_group_0 != 0 else float('inf')\n",
    "\n",
    "        return abs(ratio_group_1 - ratio_group_0), ratio_group_0, ratio_group_1, fn_group_1, fp_group_1, fn_group_0, fp_group_0\n",
    "\n",
    "    # Calculating each fairness metric\n",
    "    spd, sp_g0, sp_g1 = statistical_parity_difference()\n",
    "    eod, eod_g0, eod_g1 = equal_opportunity_difference()\n",
    "    oaed, oaed_g0, oaed_g1 = overall_accuracy_equality_difference()\n",
    "    ted, ted_g0, ted_g1, fn_group_1, fp_group_1, fn_group_0, fp_group_0 = treatment_equality_difference()\n",
    "\n",
    "    return {\n",
    "        'Statistical Parity Difference': spd,\n",
    "        'Statistical Parity Group with S=0': sp_g0,\n",
    "        'Statistical Parity Group S=1': sp_g1,\n",
    "        'Equal Opportunity Difference': eod,\n",
    "        'Equal Opportunity Group with S=0': eod_g0,\n",
    "        'Equal Opportunity Group S=1': eod_g1,\n",
    "        'Overall Accuracy Equality Difference': oaed,\n",
    "        'Overall Accuracy Group with S=0': oaed_g0,\n",
    "        'Overall Accuracy Group S=1': oaed_g1,\n",
    "        'Treatment Equality Difference': ted,\n",
    "        'Treatment Equality Group with S=0': ted_g0,\n",
    "        'Treatment Equality Group S=1': ted_g1\n",
    "        # 'False Negatives Group 1': fn_group_1,\n",
    "        # 'False Positives Group 1': fp_group_1,\n",
    "        # 'False Negatives Group 0': fn_group_0,\n",
    "        # 'False Positives Group 0': fp_group_0\n",
    "    }\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Model Training\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "# Train the model\n",
    "def training(model, data, optimizer, epochs=2000, fairness=False, alpha=0, beta=0, gamma=0, delta=0):\n",
    "    model.to(set_device())\n",
    "    data.to(set_device())\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index)\n",
    "        \n",
    "        if fairness:\n",
    "            loss = fairness_aware_loss(out[data.train_mask], data, data.x[data.train_mask, -1],\n",
    "                                       alpha=alpha, beta=beta, gamma=gamma, delta=delta)\n",
    "            \n",
    "        else:\n",
    "            # criterion = torch.nn.CrossEntropyLoss()\n",
    "            # criterion = torch.nn.BCELoss()\n",
    "            criterion = torch.nn.NLLLoss()\n",
    "            loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        metrics = test(model, data)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch} | Loss: {loss.item()} | \\n AUC_ROC: {metrics[\"AUC_ROC\"]} | F1 Score: {metrics[\"F1_Score\"]} | SPD: {metrics[\"parity\"]} | EOD: {metrics[\"equality\"]}')\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Model Testing\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "# Test the model\n",
    "def test(model, data, balanced=False):\n",
    "    # model.to('cpu')\n",
    "    # data.to('cpu')\n",
    "    model.to(set_device())\n",
    "    data.to(set_device())\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "      out = model(data.x, data.edge_index)\n",
    "\n",
    "    _, pred = model(data.x, data.edge_index).max(dim=1)\n",
    "    correct = int(pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
    "    accuracy = correct / int(data.test_mask.sum())\n",
    "    # print(f'Accuracy: {accuracy}')\n",
    "\n",
    "    # Convert model outputs to binary predictions\n",
    "    predictions = out.argmax(dim=1)\n",
    "\n",
    "    fairness_metrics = calculate_fairness(label='GoodCustomer', predictions=predictions, sens_attr='Gender', balanced=balanced)\n",
    "    fairness_metrics['Accuracy'] = accuracy\n",
    "\n",
    "    return fairness_metrics\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Print Metrics\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "# def print_metrics(metrics):\n",
    "#     for key, value in metrics.items():\n",
    "#         print(f\"\\n{key} : {value:.5f}\")\n",
    "\n",
    "def print_metrics(metrics):\n",
    "    count = -1\n",
    "\n",
    "    for key, value in metrics.items():\n",
    "        count += 1\n",
    "        if count == 3:\n",
    "            print(f\"\\n\\n{key} : {value:.5f}\")\n",
    "            count = 0\n",
    "        else:\n",
    "            print(f\"{key} : {value:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data, val=True, balanced=False):\n",
    "    model.to(set_device())\n",
    "    data.to(set_device())\n",
    "    \n",
    "    if val==True:\n",
    "      mask = data.val_mask\n",
    "    else:\n",
    "      mask = data.test_mask\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data.x, data.edge_index)\n",
    "        predictions = out.argmax(dim=1)\n",
    "\n",
    "    # Compute accuracy\n",
    "    correct = int(predictions[mask].eq(data.y[mask]).sum().item())\n",
    "    accuracy = correct / int(mask.sum())\n",
    "    \n",
    "    # Extract the predictions and the true labels\n",
    "    y_true = data.y[mask].cpu().numpy()\n",
    "    y_pred = predictions[mask].cpu().numpy()\n",
    "    \n",
    "    # Compute F1 score\n",
    "    f1 = f1_score(y_true, y_pred, average='binary')\n",
    "\n",
    "    # Compute AUC-ROC score\n",
    "    y_probs = out[mask][:, 1].cpu().numpy() \n",
    "    auc_roc = roc_auc_score(y_true, y_probs)\n",
    "    \n",
    "    fairness_metrics = fair_metric('gender', predictions, 'bin_age')\n",
    "    fairness_metrics['Accuracy'] = accuracy\n",
    "    fairness_metrics['F1_Score'] = f1\n",
    "    fairness_metrics['AUC_ROC'] = auc_roc\n",
    "\n",
    "    return fairness_metrics\n",
    "\n",
    "def fair_metric(labels, pred, sens):\n",
    "\t\n",
    "\tlabels = user_labels[labels].values\n",
    "\tsens = user_labels[sens].values\n",
    "\t\n",
    "\tidx_s0 = sens==0\n",
    "\tidx_s1 = sens==1\n",
    "\n",
    "\tidx_s0_y1 = np.bitwise_and(idx_s0, labels==1)\n",
    "\tidx_s1_y1 = np.bitwise_and(idx_s1, labels==1)\n",
    "\n",
    "\tparity = abs(sum(pred[idx_s0])/sum(idx_s0)-sum(pred[idx_s1])/sum(idx_s1))\n",
    "\tequality = abs(sum(pred[idx_s0_y1])/sum(idx_s0_y1)-sum(pred[idx_s1_y1])/sum(idx_s1_y1))\n",
    "    \n",
    "\treturn {\"parity\": parity.item(), \"equality\": equality.item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sens_attribute_tensor = torch.tensor(user_labels['bin_age'].values, dtype=torch.long)\n",
    "sens_attribute_tensor = sens_attribute_tensor.to(set_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "\tdef __init__(self, nfeat, nhid=128, nclass=2, dropout=0):\n",
    "\t\tsuper(GCN, self).__init__()\n",
    "\t\tself.body = GCN_Body(nfeat,nhid,dropout)\n",
    "\t\tself.fc = nn.Linear(nhid, nclass)\n",
    "\n",
    "\t\tfor m in self.modules():\n",
    "\t\t\tself.weights_init(m)\n",
    "\n",
    "\tdef weights_init(self, m):\n",
    "\t\tif isinstance(m, nn.Linear):\n",
    "\t\t\ttorch.nn.init.xavier_uniform_(m.weight.data)\n",
    "\t\t\tif m.bias is not None:\n",
    "\t\t\t\tm.bias.data.fill_(0.0)\n",
    "\n",
    "\tdef forward(self, x, edge_index):\n",
    "\t\tx = self.body(x, edge_index)\n",
    "\t\tx = self.fc(x)\n",
    "\t\treturn F.log_softmax(x, dim=1)\n",
    "\t\t# return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN_Body(nn.Module):\n",
    "\tdef __init__(self, nfeat, nhid, dropout):\n",
    "\t\tsuper(GCN_Body, self).__init__()\n",
    "\t\tself.gc1 = GCNConv(nfeat, nhid)\n",
    "\n",
    "\tdef forward(self, x, edge_index):\n",
    "\t\tx = self.gc1(x, edge_index)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_model = GCN(data.num_node_features, nhid=16, nclass=2)\n",
    "optimizer_gcn_model = torch.optim.Adam(gcn_model.parameters(), lr=0.01, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss: 0.6151986718177795 | \n",
      " AUC_ROC: 0.4582007971760998 | F1 Score: 0.0014182720718591184 | SPD: 0.0007968544960021973 | EOD: 0.0012943694600835443\n",
      "Epoch 10 | Loss: 0.5964589715003967 | \n",
      " AUC_ROC: 0.46234220692331923 | F1 Score: 0.0007100591715976331 | SPD: 0.00020969855540897697 | EOD: 0.00034848408540710807\n",
      "Epoch 20 | Loss: 0.5860309600830078 | \n",
      " AUC_ROC: 0.4672246215855648 | F1 Score: 0.0 | SPD: 2.0969855540897697e-05 | EOD: 4.978344077244401e-05\n",
      "Epoch 30 | Loss: 0.5811080932617188 | \n",
      " AUC_ROC: 0.4744588521745437 | F1 Score: 0.0 | SPD: 0.0 | EOD: 0.0\n",
      "Epoch 40 | Loss: 0.5781946182250977 | \n",
      " AUC_ROC: 0.48471953199159956 | F1 Score: 0.0 | SPD: 0.0 | EOD: 0.0\n",
      "Epoch 50 | Loss: 0.5754379630088806 | \n",
      " AUC_ROC: 0.4979018657505362 | F1 Score: 0.0 | SPD: 0.0 | EOD: 0.0\n",
      "Epoch 60 | Loss: 0.5725720524787903 | \n",
      " AUC_ROC: 0.5131979524240887 | F1 Score: 0.00023679848448969926 | SPD: 3.1454783311346546e-05 | EOD: 9.956688154488802e-05\n",
      "Epoch 70 | Loss: 0.5697234272956848 | \n",
      " AUC_ROC: 0.5293447567694904 | F1 Score: 0.0009468576162859509 | SPD: 0.00019921362400054932 | EOD: 0.0008961019339039922\n",
      "Epoch 80 | Loss: 0.5669046640396118 | \n",
      " AUC_ROC: 0.5452918529496861 | F1 Score: 0.001419950301739439 | SPD: 0.00023066840367391706 | EOD: 0.0010454521980136633\n",
      "Epoch 90 | Loss: 0.5640847682952881 | \n",
      " AUC_ROC: 0.5605688227188472 | F1 Score: 0.001419950301739439 | SPD: 0.00023066840367391706 | EOD: 0.0010454521980136633\n",
      "Epoch 100 | Loss: 0.5612599849700928 | \n",
      " AUC_ROC: 0.5754476529911856 | F1 Score: 0.001656412683388547 | SPD: 0.0002726081293076277 | EOD: 0.0012445859611034393\n",
      "Epoch 110 | Loss: 0.5584356784820557 | \n",
      " AUC_ROC: 0.5902085826333118 | F1 Score: 0.001656412683388547 | SPD: 0.00031454782583750784 | EOD: 0.0014437197241932154\n",
      "Epoch 120 | Loss: 0.5556141138076782 | \n",
      " AUC_ROC: 0.6050627875797697 | F1 Score: 0.0021291696238466998 | SPD: 0.0003460026055108756 | EOD: 0.0015930701047182083\n",
      "Epoch 130 | Loss: 0.5527957081794739 | \n",
      " AUC_ROC: 0.619924278546896 | F1 Score: 0.0033100839342711905 | SPD: 0.0005452162586152554 | EOD: 0.0025389555376023054\n",
      "Epoch 140 | Loss: 0.5499821901321411 | \n",
      " AUC_ROC: 0.6345203400184116 | F1 Score: 0.004961020552799433 | SPD: 0.0006640655919909477 | EOD: 0.003145446302369237\n",
      "Epoch 150 | Loss: 0.5471745133399963 | \n",
      " AUC_ROC: 0.6486583220133018 | F1 Score: 0.004961020552799433 | SPD: 0.000863279215991497 | EOD: 0.004091331735253334\n",
      "Epoch 160 | Loss: 0.5443741679191589 | \n",
      " AUC_ROC: 0.6622156841064335 | F1 Score: 0.004961020552799433 | SPD: 0.0009122190531343222 | EOD: 0.004344793502241373\n",
      "Epoch 170 | Loss: 0.5415816903114319 | \n",
      " AUC_ROC: 0.6751847985224235 | F1 Score: 0.005432215399149741 | SPD: 0.000957673997618258 | EOD: 0.004602800589054823\n",
      "Epoch 180 | Loss: 0.5387981534004211 | \n",
      " AUC_ROC: 0.6874853647696408 | F1 Score: 0.005903187721369539 | SPD: 0.0009891893714666367 | EOD: 0.00487898662686348\n",
      "Epoch 190 | Loss: 0.536023736000061 | \n",
      " AUC_ROC: 0.699100442256708 | F1 Score: 0.005903187721369539 | SPD: 0.0009543102933093905 | EOD: 0.004861016757786274\n",
      "Epoch 200 | Loss: 0.5332602858543396 | \n",
      " AUC_ROC: 0.7099464007568159 | F1 Score: 0.007549840745546773 | SPD: 0.0010487353429198265 | EOD: 0.0054359035566449165\n",
      "Epoch 210 | Loss: 0.530508279800415 | \n",
      " AUC_ROC: 0.7200057229675046 | F1 Score: 0.010835001766576374 | SPD: 0.0007834911230020225 | EOD: 0.004956876393407583\n",
      "Epoch 220 | Loss: 0.5277678370475769 | \n",
      " AUC_ROC: 0.7292550081839574 | F1 Score: 0.013173370971536109 | SPD: 0.0008570371428504586 | EOD: 0.005667688325047493\n",
      "Epoch 230 | Loss: 0.525040328502655 | \n",
      " AUC_ROC: 0.7377275537579574 | F1 Score: 0.016439643024894316 | SPD: 0.0008747040992602706 | EOD: 0.006152308080345392\n",
      "Epoch 240 | Loss: 0.5223264098167419 | \n",
      " AUC_ROC: 0.7454664777427613 | F1 Score: 0.0203914215399039 | SPD: 0.0004592768382281065 | EOD: 0.005171110387891531\n",
      "Epoch 250 | Loss: 0.5196263790130615 | \n",
      " AUC_ROC: 0.7525170317853008 | F1 Score: 0.02502046065707939 | SPD: 0.00010330486111342907 | EOD: 0.004601816646754742\n",
      "Epoch 260 | Loss: 0.5169415473937988 | \n",
      " AUC_ROC: 0.7589340319179443 | F1 Score: 0.028708133971291867 | SPD: 0.0005670029204338789 | EOD: 0.002982943318784237\n",
      "Epoch 270 | Loss: 0.5142720341682434 | \n",
      " AUC_ROC: 0.7647936277365089 | F1 Score: 0.033527357392316645 | SPD: 0.0016493438743054867 | EOD: 0.0001382920891046524\n",
      "Epoch 280 | Loss: 0.5116190314292908 | \n",
      " AUC_ROC: 0.7701577741496402 | F1 Score: 0.03923389437028439 | SPD: 0.00242437981069088 | EOD: 0.0018197651952505112\n",
      "Epoch 290 | Loss: 0.5089826583862305 | \n",
      " AUC_ROC: 0.7750416958552486 | F1 Score: 0.04716763005780347 | SPD: 0.003314476925879717 | EOD: 0.0037048980593681335\n",
      "Epoch 300 | Loss: 0.5063642263412476 | \n",
      " AUC_ROC: 0.7795319161287413 | F1 Score: 0.05682733233636259 | SPD: 0.0046550012193620205 | EOD: 0.0068474095314741135\n",
      "Epoch 310 | Loss: 0.5037636756896973 | \n",
      " AUC_ROC: 0.7836808539728856 | F1 Score: 0.06705572719990846 | SPD: 0.00639367988333106 | EOD: 0.011080199852585793\n",
      "Epoch 320 | Loss: 0.5011823773384094 | \n",
      " AUC_ROC: 0.787516848922795 | F1 Score: 0.07913587265491755 | SPD: 0.007849417626857758 | EOD: 0.014376398175954819\n",
      "Epoch 330 | Loss: 0.498619943857193 | \n",
      " AUC_ROC: 0.7910854659005571 | F1 Score: 0.08932609678878335 | SPD: 0.009539064951241016 | EOD: 0.018120229244232178\n",
      "Epoch 340 | Loss: 0.49607837200164795 | \n",
      " AUC_ROC: 0.7944185474271175 | F1 Score: 0.10449601973315394 | SPD: 0.011647656559944153 | EOD: 0.02286798134446144\n",
      "Epoch 350 | Loss: 0.49355754256248474 | \n",
      " AUC_ROC: 0.7975452399584455 | F1 Score: 0.12049799911071589 | SPD: 0.013773520477116108 | EOD: 0.027502119541168213\n",
      "Epoch 360 | Loss: 0.4910573959350586 | \n",
      " AUC_ROC: 0.8004870859080931 | F1 Score: 0.13293585072319752 | SPD: 0.01595880836248398 | EOD: 0.032213300466537476\n",
      "Epoch 370 | Loss: 0.4885801076889038 | \n",
      " AUC_ROC: 0.8032898400618784 | F1 Score: 0.1528551151872475 | SPD: 0.018059883266687393 | EOD: 0.035661302506923676\n",
      "Epoch 380 | Loss: 0.4861249327659607 | \n",
      " AUC_ROC: 0.8059478824533707 | F1 Score: 0.17176190990601709 | SPD: 0.020220203325152397 | EOD: 0.03922208398580551\n",
      "Epoch 390 | Loss: 0.4836931526660919 | \n",
      " AUC_ROC: 0.8084852142314354 | F1 Score: 0.18717207409786915 | SPD: 0.022101150825619698 | EOD: 0.04138955473899841\n",
      "Epoch 400 | Loss: 0.4812851846218109 | \n",
      " AUC_ROC: 0.810900746052917 | F1 Score: 0.20704985709749127 | SPD: 0.02406552992761135 | EOD: 0.04326637089252472\n",
      "Epoch 410 | Loss: 0.47890105843544006 | \n",
      " AUC_ROC: 0.8132234606163171 | F1 Score: 0.23088956095526125 | SPD: 0.026780547574162483 | EOD: 0.0463278666138649\n",
      "Epoch 420 | Loss: 0.47654199600219727 | \n",
      " AUC_ROC: 0.815459357615528 | F1 Score: 0.2542425177414378 | SPD: 0.0289091095328331 | EOD: 0.04874775558710098\n",
      "Epoch 430 | Loss: 0.47420862317085266 | \n",
      " AUC_ROC: 0.817617792585883 | F1 Score: 0.27290289781392985 | SPD: 0.0304263886064291 | EOD: 0.04884663224220276\n",
      "Epoch 440 | Loss: 0.4719007611274719 | \n",
      " AUC_ROC: 0.8196950085988096 | F1 Score: 0.2915410890094434 | SPD: 0.03150321543216705 | EOD: 0.04708966612815857\n",
      "Epoch 450 | Loss: 0.46961942315101624 | \n",
      " AUC_ROC: 0.8217042913688684 | F1 Score: 0.3107759476086525 | SPD: 0.033589836210012436 | EOD: 0.04882189631462097\n",
      "Epoch 460 | Loss: 0.4673649072647095 | \n",
      " AUC_ROC: 0.8236508811350283 | F1 Score: 0.3293771456596371 | SPD: 0.03428272157907486 | EOD: 0.04581230878829956\n",
      "Epoch 470 | Loss: 0.46513769030570984 | \n",
      " AUC_ROC: 0.8255294688327175 | F1 Score: 0.34347361259597625 | SPD: 0.035206329077482224 | EOD: 0.044101834297180176\n",
      "Epoch 480 | Loss: 0.4629380404949188 | \n",
      " AUC_ROC: 0.8273592781646766 | F1 Score: 0.3608950350523384 | SPD: 0.036845799535512924 | EOD: 0.04425504803657532\n",
      "Epoch 490 | Loss: 0.46076658368110657 | \n",
      " AUC_ROC: 0.8291521139083655 | F1 Score: 0.3765801729873586 | SPD: 0.0378323458135128 | EOD: 0.04265323281288147\n",
      "Epoch 500 | Loss: 0.4586235582828522 | \n",
      " AUC_ROC: 0.8308818484411346 | F1 Score: 0.39035418236623964 | SPD: 0.03886068984866142 | EOD: 0.041123539209365845\n",
      "Epoch 510 | Loss: 0.4565091133117676 | \n",
      " AUC_ROC: 0.8325596362571659 | F1 Score: 0.4055514157973174 | SPD: 0.039508234709501266 | EOD: 0.03879748284816742\n",
      "Epoch 520 | Loss: 0.454424113035202 | \n",
      " AUC_ROC: 0.8341967077961346 | F1 Score: 0.4157573515812836 | SPD: 0.04065563529729843 | EOD: 0.03852187097072601\n",
      "Epoch 530 | Loss: 0.4523681402206421 | \n",
      " AUC_ROC: 0.8358007525391367 | F1 Score: 0.4262505736576411 | SPD: 0.04149236902594566 | EOD: 0.03755444288253784\n",
      "Epoch 540 | Loss: 0.45034176111221313 | \n",
      " AUC_ROC: 0.8373674653260769 | F1 Score: 0.43866509047922153 | SPD: 0.04182937368750572 | EOD: 0.03467276692390442\n",
      "Epoch 550 | Loss: 0.44834527373313904 | \n",
      " AUC_ROC: 0.8388863941585765 | F1 Score: 0.45072959827058184 | SPD: 0.04211743548512459 | EOD: 0.03137025237083435\n",
      "Epoch 560 | Loss: 0.44637858867645264 | \n",
      " AUC_ROC: 0.8403605056574289 | F1 Score: 0.4603146228101538 | SPD: 0.04266410693526268 | EOD: 0.02800026535987854\n",
      "Epoch 570 | Loss: 0.44444185495376587 | \n",
      " AUC_ROC: 0.8417949190234748 | F1 Score: 0.46958529437882957 | SPD: 0.042439013719558716 | EOD: 0.02396547794342041\n",
      "Epoch 580 | Loss: 0.4425353407859802 | \n",
      " AUC_ROC: 0.8432047355432 | F1 Score: 0.4773931472977746 | SPD: 0.04276598244905472 | EOD: 0.02206212282180786\n",
      "Epoch 590 | Loss: 0.44065943360328674 | \n",
      " AUC_ROC: 0.8445670576506741 | F1 Score: 0.48707387608447994 | SPD: 0.04307516664266586 | EOD: 0.018443375825881958\n",
      "Epoch 600 | Loss: 0.43881383538246155 | \n",
      " AUC_ROC: 0.8458855307295279 | F1 Score: 0.4967798085291558 | SPD: 0.04327622801065445 | EOD: 0.015625715255737305\n",
      "Epoch 610 | Loss: 0.43699800968170166 | \n",
      " AUC_ROC: 0.8471579974531205 | F1 Score: 0.5048426150121065 | SPD: 0.043445833027362823 | EOD: 0.012586414813995361\n",
      "Epoch 620 | Loss: 0.4352128505706787 | \n",
      " AUC_ROC: 0.8483875075076273 | F1 Score: 0.5118238885544758 | SPD: 0.04374134540557861 | EOD: 0.01030769944190979\n",
      "Epoch 630 | Loss: 0.4334578216075897 | \n",
      " AUC_ROC: 0.8495768423967038 | F1 Score: 0.5178846482971077 | SPD: 0.04455050826072693 | EOD: 0.009214729070663452\n",
      "Epoch 640 | Loss: 0.4317329525947571 | \n",
      " AUC_ROC: 0.8507314393429406 | F1 Score: 0.524129713167078 | SPD: 0.044528357684612274 | EOD: 0.006352663040161133\n",
      "Epoch 650 | Loss: 0.43003806471824646 | \n",
      " AUC_ROC: 0.8518399777213899 | F1 Score: 0.5289928789420143 | SPD: 0.04443983733654022 | EOD: 0.0034273862838745117\n",
      "Epoch 660 | Loss: 0.42837315797805786 | \n",
      " AUC_ROC: 0.8529210285782176 | F1 Score: 0.5350425908745889 | SPD: 0.044358350336551666 | EOD: 0.0005880594253540039\n",
      "Epoch 670 | Loss: 0.4267381429672241 | \n",
      " AUC_ROC: 0.8539598086486868 | F1 Score: 0.539469264360094 | SPD: 0.04442711919546127 | EOD: 0.0019841790199279785\n",
      "Epoch 680 | Loss: 0.42513254284858704 | \n",
      " AUC_ROC: 0.8549605495206972 | F1 Score: 0.5451507810542143 | SPD: 0.04454813897609711 | EOD: 0.004470705986022949\n",
      "Epoch 690 | Loss: 0.4235563576221466 | \n",
      " AUC_ROC: 0.8559251688179296 | F1 Score: 0.5481802282002165 | SPD: 0.04483705013990402 | EOD: 0.005789458751678467\n",
      "Epoch 700 | Loss: 0.4220092296600342 | \n",
      " AUC_ROC: 0.8568510843936452 | F1 Score: 0.5522846007131603 | SPD: 0.04600260406732559 | EOD: 0.005497604608535767\n",
      "Epoch 710 | Loss: 0.4204910397529602 | \n",
      " AUC_ROC: 0.8577395279887974 | F1 Score: 0.5565375402659619 | SPD: 0.04593517631292343 | EOD: 0.00794297456741333\n",
      "Epoch 720 | Loss: 0.41900166869163513 | \n",
      " AUC_ROC: 0.8586035171354272 | F1 Score: 0.5613025244634487 | SPD: 0.046223998069763184 | EOD: 0.009528875350952148\n",
      "Epoch 730 | Loss: 0.417540580034256 | \n",
      " AUC_ROC: 0.8594221881828198 | F1 Score: 0.5644513644185857 | SPD: 0.046030908823013306 | EOD: 0.012408465147018433\n",
      "Epoch 740 | Loss: 0.41610777378082275 | \n",
      " AUC_ROC: 0.8602217992849399 | F1 Score: 0.5673886391499795 | SPD: 0.046285055577754974 | EOD: 0.013876199722290039\n",
      "Epoch 750 | Loss: 0.41470232605934143 | \n",
      " AUC_ROC: 0.8609890599806345 | F1 Score: 0.5712889829818418 | SPD: 0.04631560295820236 | EOD: 0.01569691300392151\n",
      "Epoch 760 | Loss: 0.4133249521255493 | \n",
      " AUC_ROC: 0.8617301242280764 | F1 Score: 0.5743523105660684 | SPD: 0.04664312303066254 | EOD: 0.01678451895713806\n",
      "Epoch 770 | Loss: 0.41197413206100464 | \n",
      " AUC_ROC: 0.8624390350527131 | F1 Score: 0.5773997569866343 | SPD: 0.0466529056429863 | EOD: 0.01858210563659668\n",
      "Epoch 780 | Loss: 0.4106503427028656 | \n",
      " AUC_ROC: 0.8631149546808327 | F1 Score: 0.5794452979704051 | SPD: 0.046896792948246 | EOD: 0.019669294357299805\n",
      "Epoch 790 | Loss: 0.40935298800468445 | \n",
      " AUC_ROC: 0.8637600784118222 | F1 Score: 0.5821581110484325 | SPD: 0.047388434410095215 | EOD: 0.020507991313934326\n",
      "Epoch 800 | Loss: 0.4080817401409149 | \n",
      " AUC_ROC: 0.864387547189147 | F1 Score: 0.5848601735776278 | SPD: 0.04753787815570831 | EOD: 0.02174907922744751\n",
      "Epoch 810 | Loss: 0.40683627128601074 | \n",
      " AUC_ROC: 0.8649880671831861 | F1 Score: 0.5867072877415216 | SPD: 0.04718779772520065 | EOD: 0.024144083261489868\n",
      "Epoch 820 | Loss: 0.40561628341674805 | \n",
      " AUC_ROC: 0.8655588212908345 | F1 Score: 0.590255591054313 | SPD: 0.04697711765766144 | EOD: 0.026363074779510498\n",
      "Epoch 830 | Loss: 0.4044210612773895 | \n",
      " AUC_ROC: 0.8661087805733709 | F1 Score: 0.5925925925925926 | SPD: 0.04691723734140396 | EOD: 0.027553945779800415\n",
      "Epoch 840 | Loss: 0.40325045585632324 | \n",
      " AUC_ROC: 0.8666401735563348 | F1 Score: 0.5944356120826709 | SPD: 0.046706996858119965 | EOD: 0.029568642377853394\n",
      "Epoch 850 | Loss: 0.40210384130477905 | \n",
      " AUC_ROC: 0.8671511063490123 | F1 Score: 0.5956973882670477 | SPD: 0.04701396822929382 | EOD: 0.030130505561828613\n",
      "Epoch 860 | Loss: 0.4009815752506256 | \n",
      " AUC_ROC: 0.8676386526766526 | F1 Score: 0.5991928464034185 | SPD: 0.04667775332927704 | EOD: 0.033322036266326904\n",
      "Epoch 870 | Loss: 0.3998822867870331 | \n",
      " AUC_ROC: 0.8681032871985828 | F1 Score: 0.6000473971087764 | SPD: 0.04661429673433304 | EOD: 0.03476184606552124\n",
      "Epoch 880 | Loss: 0.3988061845302582 | \n",
      " AUC_ROC: 0.8685524407065657 | F1 Score: 0.6021284982262515 | SPD: 0.046715110540390015 | EOD: 0.03557717800140381\n",
      "Epoch 890 | Loss: 0.3977530300617218 | \n",
      " AUC_ROC: 0.8689739548019422 | F1 Score: 0.60388334250452 | SPD: 0.04680188000202179 | EOD: 0.03683602809906006\n",
      "Epoch 900 | Loss: 0.3967220187187195 | \n",
      " AUC_ROC: 0.8693814094880554 | F1 Score: 0.605537689230528 | SPD: 0.04680830240249634 | EOD: 0.03829401731491089\n",
      "Epoch 910 | Loss: 0.39571285247802734 | \n",
      " AUC_ROC: 0.8697791526443401 | F1 Score: 0.6086344439230408 | SPD: 0.046559564769268036 | EOD: 0.03988790512084961\n",
      "Epoch 920 | Loss: 0.3947250545024872 | \n",
      " AUC_ROC: 0.8701558209265099 | F1 Score: 0.6101218369259607 | SPD: 0.046311117708683014 | EOD: 0.04163983464241028\n",
      "Epoch 930 | Loss: 0.3937586545944214 | \n",
      " AUC_ROC: 0.8705114000947847 | F1 Score: 0.6112107273719498 | SPD: 0.04610802233219147 | EOD: 0.043097615242004395\n",
      "Epoch 940 | Loss: 0.3928126394748688 | \n",
      " AUC_ROC: 0.8708541777010127 | F1 Score: 0.6145841422691621 | SPD: 0.04607228934764862 | EOD: 0.045117080211639404\n",
      "Epoch 950 | Loss: 0.3918873369693756 | \n",
      " AUC_ROC: 0.871178405620745 | F1 Score: 0.615742535866615 | SPD: 0.04588322341442108 | EOD: 0.04679194092750549\n",
      "Epoch 960 | Loss: 0.3909819424152374 | \n",
      " AUC_ROC: 0.8714953522664023 | F1 Score: 0.6171348966798235 | SPD: 0.04593168944120407 | EOD: 0.04742613434791565\n",
      "Epoch 970 | Loss: 0.39009615778923035 | \n",
      " AUC_ROC: 0.8717968985901977 | F1 Score: 0.6189483437572387 | SPD: 0.046025410294532776 | EOD: 0.04887956380844116\n",
      "Epoch 980 | Loss: 0.3892296254634857 | \n",
      " AUC_ROC: 0.8720784522631437 | F1 Score: 0.6207906295754027 | SPD: 0.045808322727680206 | EOD: 0.05045509338378906\n",
      "Epoch 990 | Loss: 0.3883819878101349 | \n",
      " AUC_ROC: 0.8723479733221522 | F1 Score: 0.6227314672408489 | SPD: 0.046024322509765625 | EOD: 0.050745755434036255\n"
     ]
    }
   ],
   "source": [
    "training(model=gcn_model, \n",
    "         data=data, \n",
    "         optimizer=optimizer_gcn_model, \n",
    "         fairness=False,  \n",
    "         epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the values for the GCN model\n",
      "parity : 0.04591\n",
      "equality : 0.05184\n",
      "Accuracy : 0.85353\n",
      "\n",
      "\n",
      "F1_Score : 0.62449\n",
      "AUC_ROC : 0.87258\n"
     ]
    }
   ],
   "source": [
    "print(\"Here are the values for the GCN model\")\n",
    "\n",
    "metrics_gcn_model = test(gcn_model, data)\n",
    "\n",
    "print_metrics(metrics_gcn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss: 0.7154015898704529 | \n",
      " AUC_ROC: 0.28981126667042123 | F1 Score: 0.0006988120195667364 | SPD: 0.005784710869193077 | EOD: 0.0011948025785386562\n",
      "Epoch 10 | Loss: 0.592928946018219 | \n",
      " AUC_ROC: 0.5173302297258584 | F1 Score: 0.00753473039792795 | SPD: 0.0023349570110440254 | EOD: 0.006431572139263153\n",
      "Epoch 20 | Loss: 0.5235864520072937 | \n",
      " AUC_ROC: 0.7881768579702766 | F1 Score: 0.04535987040037028 | SPD: 0.0013826140202581882 | EOD: 0.003806181252002716\n",
      "Epoch 30 | Loss: 0.4776657819747925 | \n",
      " AUC_ROC: 0.831259212099218 | F1 Score: 0.17817947062621048 | SPD: 0.013948183506727219 | EOD: 0.012088701128959656\n",
      "Epoch 40 | Loss: 0.43756547570228577 | \n",
      " AUC_ROC: 0.8557631723362468 | F1 Score: 0.4623223384285331 | SPD: 0.03427240252494812 | EOD: 0.00240248441696167\n",
      "Here are the values for the GCN model\n",
      "parity : 0.04365\n",
      "equality : 0.02798\n",
      "Accuracy : 0.84200\n",
      "\n",
      "\n",
      "F1_Score : 0.57217\n",
      "AUC_ROC : 0.86603\n"
     ]
    }
   ],
   "source": [
    "training(model=gcn_model, \n",
    "         data=data, \n",
    "         optimizer=optimizer_gcn_model, \n",
    "         fairness=False,  \n",
    "         epochs=50)\n",
    "\n",
    "print(\"Here are the values for the GCN model\")\n",
    "\n",
    "metrics_gcn_model = test(gcn_model, data)\n",
    "\n",
    "print_metrics(metrics_gcn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FairnessAwareMessagePassingLayer(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(FairnessAwareMessagePassingLayer, self).__init__(aggr='mean')  \n",
    "        self.lin = nn.Linear(in_channels, out_channels)\n",
    "        self.sensitive_attr = sens_attribute_tensor\n",
    "        self.bias_correction = nn.Parameter(torch.rand(1))\n",
    "\n",
    "    def forward(self, x, edge_index):        \n",
    "        # Add self-loops \n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "\n",
    "        x = self.lin(x)\n",
    "\n",
    "        return self.propagate(edge_index, size=(x.size(0), x.size(0)), x=x)\n",
    "    \n",
    "    def message(self, x_j, edge_index, size):\n",
    "        row, col = edge_index\n",
    "        deg = degree(row, size[0], dtype=x_j.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "        \n",
    "        group_difference = self.sensitive_attr[row] - self.sensitive_attr[col]\n",
    "        \n",
    "        # Adjust messages based on statistical parity\n",
    "        fairness_adjustment = (1 + self.bias_correction * group_difference.view(-1, 1))\n",
    "\n",
    "        return fairness_adjustment * norm.view(-1, 1) * x_j\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        return aggr_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FairMP_GCN(torch.nn.Module):\n",
    "    def __init__(self, data, layers=1, hidden=128, dropout=0):\n",
    "        super(FairMP_GCN, self).__init__()\n",
    "        self.conv1 = FairnessAwareMessagePassingLayer(data.num_node_features, hidden)\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        \n",
    "        for i in range(layers - 1):\n",
    "            self.convs.append(FairnessAwareMessagePassingLayer(hidden, hidden))\n",
    "        \n",
    "        # self.conv2 = FairnessAwareMessagePassingLayer(hidden, 2)\n",
    "        self.fc = nn.Linear(hidden, 2)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, edge_index, *args, **kwargs):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        # x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        for conv in self.convs:\n",
    "            x = F.relu(conv(x, edge_index))\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        # x = self.conv2(x, edge_index)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fair_gcn_model = FairMP_GCN(data, hidden=16)\n",
    "optimizer_Fair_gcn_model = torch.optim.Adam(Fair_gcn_model.parameters(), lr=0.01, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss: 0.690586268901825 | \n",
      " AUC_ROC: 0.35402714856739625 | F1 Score: 0.01308564084589321 | SPD: 0.005428011063486338 | EOD: 0.011536752805113792\n",
      "Epoch 10 | Loss: 0.6365414261817932 | \n",
      " AUC_ROC: 0.41586195891002364 | F1 Score: 0.0 | SPD: 0.0 | EOD: 0.0\n",
      "Epoch 20 | Loss: 0.5943252444267273 | \n",
      " AUC_ROC: 0.8310719827277167 | F1 Score: 0.13972934316206406 | SPD: 0.0005518160760402679 | EOD: 0.025728903710842133\n",
      "Epoch 30 | Loss: 0.5547952651977539 | \n",
      " AUC_ROC: 0.8901853575524458 | F1 Score: 0.22962497381102037 | SPD: 0.005978608503937721 | EOD: 0.024777323007583618\n",
      "Epoch 40 | Loss: 0.5184928774833679 | \n",
      " AUC_ROC: 0.903465677609534 | F1 Score: 0.3414442700156986 | SPD: 0.01719280704855919 | EOD: 0.01047012209892273\n"
     ]
    }
   ],
   "source": [
    "training(model=Fair_gcn_model, \n",
    "         data=data, \n",
    "         optimizer=optimizer_Fair_gcn_model, \n",
    "         fairness=False,  \n",
    "         epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the values for the GCN model\n",
      "parity : 0.02237\n",
      "equality : 0.01013\n",
      "Accuracy : 0.81073\n",
      "\n",
      "\n",
      "F1_Score : 0.40389\n",
      "AUC_ROC : 0.90681\n"
     ]
    }
   ],
   "source": [
    "print(\"Here are the values for the GCN model\")\n",
    "\n",
    "metrics_Fair_gcn_model = test(Fair_gcn_model, data)\n",
    "\n",
    "print_metrics(metrics_Fair_gcn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the values for the GCN model\n",
      "parity : 0.03111\n",
      "equality : 0.02125\n",
      "Accuracy : 0.82589\n",
      "\n",
      "\n",
      "F1_Score : 0.48430\n",
      "AUC_ROC : 0.68408\n"
     ]
    }
   ],
   "source": [
    "print(\"Here are the values for the GCN model\")\n",
    "\n",
    "metrics_Fair_gcn_model = test(Fair_gcn_model, data)\n",
    "\n",
    "print_metrics(metrics_Fair_gcn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A-FAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch.nn import Linear, Parameter\n",
    "from torch_geometric.utils import add_self_loops, softmax\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Attention_FairMessagePassing(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Attention_FairMessagePassing, self).__init__(aggr='add') \n",
    "        self.lin = Linear(in_channels, out_channels) \n",
    "        self.att = Linear(2 * out_channels, 1) \n",
    "        \n",
    "        self.sensitive_attr = sens_attribute_tensor \n",
    "        self.bias_correction = Parameter(torch.rand(1))  \n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "\n",
    "        x = self.lin(x)\n",
    "\n",
    "        return self.propagate(edge_index, size=(x.size(0), x.size(0)), x=x)\n",
    "\n",
    "    def message(self, edge_index, x_i, x_j, size_i):\n",
    "        x_cat = torch.cat([x_i, x_j], dim=-1)  \n",
    "        alpha = self.att(x_cat)\n",
    "\n",
    "        row, col = edge_index\n",
    "        group_difference = self.sensitive_attr[row] - self.sensitive_attr[col]\n",
    "\n",
    "        fairness_adjustment = self.bias_correction * group_difference.view(-1, 1)\n",
    "        alpha = alpha + fairness_adjustment\n",
    "\n",
    "        alpha = softmax(alpha, edge_index[0], num_nodes=size_i)\n",
    "\n",
    "        return alpha * x_j\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        return aggr_out\n",
    "    \n",
    "# GCN class that takes in the data as an input for dimensions of the convolutions\n",
    "class Fair_Attention_MP_GCN(torch.nn.Module):\n",
    "    def __init__(self, data, layers=1, hidden=128, dropout=0):\n",
    "        super(Fair_Attention_MP_GCN, self).__init__()\n",
    "        self.conv1 = Attention_FairMessagePassing(data.num_node_features, hidden)\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        \n",
    "        for i in range(layers - 1):\n",
    "            self.convs.append(Attention_FairMessagePassing(hidden, hidden))\n",
    "        \n",
    "        # self.conv2 = Attention_FairMessagePassing(hidden, 2)\n",
    "        self.fc = Linear(hidden, 2)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, edge_index, *args, **kwargs):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        # x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        for conv in self.convs:\n",
    "            x = F.relu(conv(x, edge_index))\n",
    "            # x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        # x = self.conv2(x, edge_index)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss: 0.943186342716217 | \n",
      " AUC_ROC: 0.5154655590396341 | F1 Score: 0.40370963501207063 | SPD: 0.0 | EOD: 0.0\n",
      "Epoch 10 | Loss: 0.6069545745849609 | \n",
      " AUC_ROC: 0.49094220184921106 | F1 Score: 0.0 | SPD: 0.0 | EOD: 0.0\n",
      "Epoch 20 | Loss: 0.5302107930183411 | \n",
      " AUC_ROC: 0.780581656083069 | F1 Score: 0.00023679848448969926 | SPD: 9.436435357201844e-05 | EOD: 0.0004480509669519961\n",
      "Epoch 30 | Loss: 0.4590913653373718 | \n",
      " AUC_ROC: 0.8944414283799714 | F1 Score: 0.0011834319526627217 | SPD: 0.00029357796302065253 | EOD: 0.0013939363416284323\n",
      "Epoch 40 | Loss: 0.3787717819213867 | \n",
      " AUC_ROC: 0.9833063382707635 | F1 Score: 0.042390548992355795 | SPD: 0.0050068264827132225 | EOD: 0.028081420809030533\n"
     ]
    }
   ],
   "source": [
    "Fair_gat_model = Fair_Attention_MP_GCN(data, hidden=16)\n",
    "optimizer_Fair_gat_model = torch.optim.Adam(Fair_gat_model.parameters(), lr=0.01, weight_decay=1e-5)\n",
    "\n",
    "training(model=Fair_gat_model, \n",
    "         data=data, \n",
    "         optimizer=optimizer_Fair_gat_model, \n",
    "         fairness=False,  \n",
    "         epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the values for the FairGAT model\n",
      "parity : 0.01047\n",
      "equality : 0.06353\n",
      "Accuracy : 0.76051\n",
      "\n",
      "\n",
      "F1_Score : 0.10678\n",
      "AUC_ROC : 0.99429\n"
     ]
    }
   ],
   "source": [
    "print(\"Here are the values for the FairGAT model\")\n",
    "\n",
    "metrics_Fair_gat_model = test(Fair_gat_model, data)\n",
    "\n",
    "print_metrics(metrics_Fair_gat_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(nn.Module):\n",
    "\tdef __init__(self, nfeat, nhid=128, nclass=2, dropout=0):\n",
    "\t\tsuper(GAT, self).__init__()\n",
    "\t\tself.body = GAT_Body(nfeat,nhid,dropout)\n",
    "\t\tself.fc = nn.Linear(nhid, nclass)\n",
    "\n",
    "\t\tfor m in self.modules():\n",
    "\t\t\tself.weights_init(m)\n",
    "\n",
    "\tdef weights_init(self, m):\n",
    "\t\tif isinstance(m, nn.Linear):\n",
    "\t\t\ttorch.nn.init.xavier_uniform_(m.weight.data)\n",
    "\t\t\tif m.bias is not None:\n",
    "\t\t\t\tm.bias.data.fill_(0.0)\n",
    "\n",
    "\tdef forward(self, x, edge_index):\n",
    "\t\tx = self.body(x, edge_index)\n",
    "\t\tx = self.fc(x)\n",
    "\t\treturn F.log_softmax(x, dim=1)\n",
    "\t\t# return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATConv\n",
    "\n",
    "class GAT_Body(nn.Module):\n",
    "\tdef __init__(self, nfeat, nhid, dropout):\n",
    "\t\tsuper(GAT_Body, self).__init__()\n",
    "\t\tself.gc1 = GATConv(nfeat, nhid)\n",
    "\n",
    "\tdef forward(self, x, edge_index):\n",
    "\t\tx = self.gc1(x, edge_index)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss: 0.5749228596687317 | \n",
      " AUC_ROC: 0.5852403448181667 | F1 Score: 0.03706230104592997 | SPD: 0.017376001924276352 | EOD: 0.024556681513786316\n",
      "Epoch 10 | Loss: 0.495073527097702 | \n",
      " AUC_ROC: 0.7977187208225428 | F1 Score: 0.16602067183462532 | SPD: 0.017557242885231972 | EOD: 0.02045833319425583\n",
      "Epoch 20 | Loss: 0.4108549654483795 | \n",
      " AUC_ROC: 0.8856521094109684 | F1 Score: 0.5775786188685285 | SPD: 0.044105589389801025 | EOD: 0.037001967430114746\n",
      "Epoch 30 | Loss: 0.3071121275424957 | \n",
      " AUC_ROC: 0.9542107349285638 | F1 Score: 0.7325951557093425 | SPD: 0.07764032483100891 | EOD: 0.0003832578659057617\n",
      "Epoch 40 | Loss: 0.20482370257377625 | \n",
      " AUC_ROC: 0.9816319846149621 | F1 Score: 0.8563790101964684 | SPD: 0.1038682758808136 | EOD: 0.049774885177612305\n"
     ]
    }
   ],
   "source": [
    "gat_model = GAT(data.num_node_features, nhid=16)\n",
    "optimizer_gat_model = torch.optim.Adam(gat_model.parameters(), lr=0.01, weight_decay=1e-5)\n",
    "\n",
    "training(model=gat_model, \n",
    "         data=data, \n",
    "         optimizer=optimizer_gat_model, \n",
    "         fairness=False,  \n",
    "         epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the values for the GAT model\n",
      "parity : 0.10312\n",
      "equality : 0.02911\n",
      "Accuracy : 0.95993\n",
      "\n",
      "\n",
      "F1_Score : 0.92187\n",
      "AUC_ROC : 0.98939\n"
     ]
    }
   ],
   "source": [
    "print(\"Here are the values for the GAT model\")\n",
    "\n",
    "metrics_gat_model = test(gat_model, data)\n",
    "\n",
    "print_metrics(metrics_gat_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Values for the FairGAT model - same model specifications as the one from Carlos,\n",
    "but with one A-FAME instead of one GCNConv layer\n",
    "\n",
    "parity : 0.00706\n",
    "equality : 0.00207\n",
    "Accuracy : 0.68000\n",
    "F1_Score : 0.80952\n",
    "AUC_ROC : 0.67496"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

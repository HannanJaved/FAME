{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Necessities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Imports\n",
    "# ------------------------------------------------------------------\n",
    "# Basic data processing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Graph data processing libraries\n",
    "import networkx as nx\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import from_networkx\n",
    "\n",
    "# Libraries for (G)NNs\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Helper functions\n",
    "# ------------------------------------------------------------------\n",
    "def show_df_info(df):\n",
    "    print(df.info())\n",
    "    print('####### Repeat ####### \\n', df.duplicated().any())\n",
    "    print('####### Count ####### \\n', df.nunique())\n",
    "    print('####### Example ####### \\n',df.head())\n",
    "\n",
    "def label_statics(label_df, label_list):\n",
    "    print(\"####### nCount #######\")\n",
    "    for label in label_list:\n",
    "        print(label_df[label].value_counts())\n",
    "    print(\"####### nPercent #######\")\n",
    "    for label in label_list:\n",
    "        print(label_df[label].value_counts()/label_df.shape[0])\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Data stuff\n",
    "# ------------------------------------------------------------------\n",
    "base_path = os.getcwd()\n",
    "input_ali_data_path = base_path\n",
    "\n",
    "# Load the data files\n",
    "user_labels_path = os.path.join(input_ali_data_path, \"region_job_2.csv\")\n",
    "user_edges_path = os.path.join(input_ali_data_path, \"region_job_relationship_2.csv\")\n",
    "\n",
    "# Create dataframes to store the information from the .csv files\n",
    "user_labels = pd.read_csv(user_labels_path)\n",
    "user_edges = pd.read_csv(user_edges_path)\n",
    "\n",
    "user_edges = user_edges[user_edges['uid1'].isin(user_labels['user_id']) & user_edges['uid2'].isin(user_labels['user_id'])]\n",
    "user_labels_train = user_labels\n",
    "user_labels_train = user_labels_train.drop(columns=['I_am_working_in_field'])\n",
    "\n",
    "# Extract node features from user_labels dataframe\n",
    "node_features = user_labels_train.iloc[:, 1:] # Replace 'attribute1', 'attribute2', ... with the actual attribute columns you want to use\n",
    "node_features = torch.tensor(node_features.values, dtype=torch.float)\n",
    "\n",
    "# Extract edges from user_edges dataframe\n",
    "edges = user_edges[['uid1', 'uid2']]\n",
    "edges['uid1'] = edges['uid1'].map(dict(zip(user_labels['user_id'], range(len(user_labels)))))\n",
    "edges['uid2'] = edges['uid2'].map(dict(zip(user_labels['user_id'], range(len(user_labels)))))\n",
    "\n",
    "# Convert edges dataframe to tensor\n",
    "edges_tensor = torch.tensor(edges.values, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# Create edge_index tensor\n",
    "edge_index = edges_tensor\n",
    "\n",
    "user_labels['I_am_working_in_field'] = user_labels['I_am_working_in_field'].map({-1: 0, 0: 1, 1: 1, 2: 1, 3: 1, 4: 1})\n",
    "\n",
    "# Create torch-geometric data\n",
    "data = Data(x=node_features, edge_index=edge_index)\n",
    "\n",
    "num_nodes = node_features.size(0)\n",
    "num_classes = 2 \n",
    "num_node_features = data.num_node_features\n",
    "\n",
    "# Create masks for training, and testing\n",
    "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "\n",
    "# 60-20-20 Train and Test data split\n",
    "num_train = int(num_nodes * 0.6)\n",
    "num_val = int(num_nodes * 0.8)\n",
    "train_mask[:num_train] = True\n",
    "val_mask[num_train:num_val] = True\n",
    "test_mask[num_val:] = True\n",
    "\n",
    "data.train_mask = train_mask\n",
    "data.test_mask = test_mask\n",
    "data.val_mask = val_mask\n",
    "\n",
    "# Labels from the data (in this case: Job Classification)\n",
    "data.y = torch.tensor(user_labels['I_am_working_in_field'].values, dtype=torch.long)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Set Device\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "def set_device():\n",
    "    return torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Loss\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "def fairness_aware_loss(output, data, sensitive_attr, alpha=0, beta=0, gamma=0, delta=0):\n",
    "    target = data.y[data.train_mask]\n",
    "    # standard_loss = F.cross_entropy(output, target)\n",
    "    standard_loss = F.nll_loss(output, target)\n",
    "\n",
    "    labels = data.y[train_mask]\n",
    "    pos_prob = torch.exp(output[:, 1])\n",
    "    neg_prob = torch.exp(output[:, 0])\n",
    "    # pos_prob = torch.sigmoid(output[:, 1])\n",
    "    # neg_prob = 1 - pos_prob\n",
    "    predictions = output.argmax(dim=1)\n",
    "\n",
    "    # Statistical Parity Regularization\n",
    "    sp_reg = torch.abs(pos_prob[sensitive_attr == 1].mean() - pos_prob[sensitive_attr == 0].mean())\n",
    "\n",
    "    # # Calculating FPR and TPR for each group\n",
    "    # fpr_group1 = ((predictions == 1) & (labels == 0) & (sensitive_attr == 1)).float().mean()\n",
    "    # fpr_group0 = ((predictions == 1) & (labels == 0) & (sensitive_attr == 0)).float().mean()\n",
    "    # tpr_group1 = ((predictions == 1) & (labels == 1) & (sensitive_attr == 1)).float().mean()\n",
    "    # tpr_group0 = ((predictions == 1) & (labels == 1) & (sensitive_attr == 0)).float().mean()\n",
    "\n",
    "    # Treatment Equality Regularization\n",
    "    fp_diff = (neg_prob * (labels == 0) * (sensitive_attr == 1)).float().mean() - \\\n",
    "              (neg_prob * (labels == 0) * (sensitive_attr == 0)).float().mean()\n",
    "    fn_diff = (pos_prob * (labels == 1) * (sensitive_attr == 1)).float().mean() - \\\n",
    "              (pos_prob * (labels == 1) * (sensitive_attr == 0)).float().mean()\n",
    "    treatment_reg = torch.abs(fp_diff) + torch.abs(fn_diff)\n",
    "    # treatment_reg = torch.abs(fn_diff)\n",
    "\n",
    "    # fn_group_1 = ((predictions == 0) & (labels == 1) & (sensitive_attr == 1)).sum()\n",
    "    # fp_group_1 = ((predictions == 1) & (labels == 0) & (sensitive_attr == 1)).sum()\n",
    "\n",
    "    # fn_group_0 = ((predictions == 0) & (labels == 1) & (sensitive_attr == 0)).sum()\n",
    "    # fp_group_0 = ((predictions == 1) & (labels == 0) & (sensitive_attr == 0)).sum()\n",
    "    \n",
    "    # ratio_group_1 = fn_group_1 / fp_group_1 if fp_group_1 != 0 else torch.tensor(float('inf'))\n",
    "    # ratio_group_0 = fn_group_0 / fp_group_0 if fp_group_0 != 0 else torch.tensor(float('inf'))\n",
    "    # treatment_reg = torch.abs(ratio_group_1 - ratio_group_0)\n",
    "\n",
    "    # Equal Opportunity Difference Regularization\n",
    "    eod_reg = torch.abs((pos_prob * (labels == 1) * (sensitive_attr == 1)).float().mean() - \\\n",
    "                        (pos_prob * (labels == 1) * (sensitive_attr == 0)).float().mean())\n",
    "\n",
    "    # Overall Accuracy Equality Difference Regularization\n",
    "    oaed_reg = torch.abs((pos_prob * (sensitive_attr == 1)).float().mean() - \\\n",
    "                         (pos_prob * (sensitive_attr == 0)).float().mean())\n",
    "\n",
    "    penalty = alpha + beta + gamma + delta\n",
    "    \n",
    "    # Combine losses\n",
    "    combined_loss = (1-penalty)*standard_loss\n",
    "    + alpha * sp_reg\n",
    "    + beta * treatment_reg\n",
    "    + gamma * eod_reg\n",
    "    + delta * oaed_reg\n",
    "    \n",
    "    return combined_loss\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Fairness Metrics\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "def calculate_fairness(label, predictions, sens_attr='Gender', balanced=False):\n",
    "    \"\"\"\n",
    "    Calculate various fairness metrics.\n",
    "\n",
    "    Args:\n",
    "    label: Actual labels (binary).\n",
    "    predictions: Model predictions (binary).\n",
    "    sens_attr: Binary sensitive attribute for fairness evaluation.\n",
    "\n",
    "    Returns:\n",
    "    A dictionary containing SPD, EOD, OAED, and TED values.\n",
    "    \"\"\"\n",
    "    if balanced is False:\n",
    "        labels = torch.tensor(user_labels[label].values, dtype=torch.long)\n",
    "        sensitive_attribute = torch.tensor(user_labels[sens_attr].values, dtype=torch.long)\n",
    "    else:\n",
    "        labels = torch.tensor(filtered_user_labels[label].values, dtype=torch.long)\n",
    "        sensitive_attribute = torch.tensor(filtered_user_labels[sens_attr].values, dtype=torch.long)\n",
    "    \n",
    "    labels = labels.to(set_device())\n",
    "    sensitive_attribute = sensitive_attribute.to(set_device())\n",
    "\n",
    "    predictions = predictions.float()\n",
    "    labels = labels.float()\n",
    "    sensitive_attribute = sensitive_attribute.float()\n",
    "\n",
    "    def statistical_parity_difference():\n",
    "        prob_group_1 = predictions[sensitive_attribute == 1].mean()\n",
    "        prob_group_0 = predictions[sensitive_attribute == 0].mean()\n",
    "        return abs(prob_group_1 - prob_group_0), prob_group_0, prob_group_1\n",
    "\n",
    "    def equal_opportunity_difference():\n",
    "        tpr_group_1 = predictions[(labels == 1) & (sensitive_attribute == 1)].mean()\n",
    "        tpr_group_0 = predictions[(labels == 1) & (sensitive_attribute == 0)].mean()\n",
    "        return abs(tpr_group_1 - tpr_group_0), tpr_group_0, tpr_group_1\n",
    "\n",
    "    def overall_accuracy_equality_difference():\n",
    "        acc_group_1 = (predictions[sensitive_attribute == 1] == labels[sensitive_attribute == 1]).float().mean()\n",
    "        acc_group_0 = (predictions[sensitive_attribute == 0] == labels[sensitive_attribute == 0]).float().mean()\n",
    "        return abs(acc_group_1 - acc_group_0), acc_group_0, acc_group_1\n",
    "\n",
    "    def treatment_equality_difference():\n",
    "        fn_group_1 = ((predictions == 0) & (labels == 1) & (sensitive_attribute == 1)).sum()\n",
    "        fp_group_1 = ((predictions == 1) & (labels == 0) & (sensitive_attribute == 1)).sum()\n",
    "\n",
    "        fn_group_0 = ((predictions == 0) & (labels == 1) & (sensitive_attribute == 0)).sum()\n",
    "        fp_group_0 = ((predictions == 1) & (labels == 0) & (sensitive_attribute == 0)).sum()\n",
    "\n",
    "        ratio_group_1 = fn_group_1 / fp_group_1 if fp_group_1 != 0 else float('inf')\n",
    "        ratio_group_0 = fn_group_0 / fp_group_0 if fp_group_0 != 0 else float('inf')\n",
    "\n",
    "        return abs(ratio_group_1 - ratio_group_0), ratio_group_0, ratio_group_1, fn_group_1, fp_group_1, fn_group_0, fp_group_0\n",
    "\n",
    "    # Calculating each fairness metric\n",
    "    spd, sp_g0, sp_g1 = statistical_parity_difference()\n",
    "    eod, eod_g0, eod_g1 = equal_opportunity_difference()\n",
    "    oaed, oaed_g0, oaed_g1 = overall_accuracy_equality_difference()\n",
    "    ted, ted_g0, ted_g1, fn_group_1, fp_group_1, fn_group_0, fp_group_0 = treatment_equality_difference()\n",
    "\n",
    "    return {\n",
    "        'Statistical Parity Difference': spd,\n",
    "        'Statistical Parity Group with S=0': sp_g0,\n",
    "        'Statistical Parity Group S=1': sp_g1,\n",
    "        'Equal Opportunity Difference': eod,\n",
    "        'Equal Opportunity Group with S=0': eod_g0,\n",
    "        'Equal Opportunity Group S=1': eod_g1,\n",
    "        'Overall Accuracy Equality Difference': oaed,\n",
    "        'Overall Accuracy Group with S=0': oaed_g0,\n",
    "        'Overall Accuracy Group S=1': oaed_g1,\n",
    "        'Treatment Equality Difference': ted,\n",
    "        'Treatment Equality Group with S=0': ted_g0,\n",
    "        'Treatment Equality Group S=1': ted_g1\n",
    "        # 'False Negatives Group 1': fn_group_1,\n",
    "        # 'False Positives Group 1': fp_group_1,\n",
    "        # 'False Negatives Group 0': fn_group_0,\n",
    "        # 'False Positives Group 0': fp_group_0\n",
    "    }\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Model Training\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "# Train the model\n",
    "def training(model, data, optimizer, epochs=1000, fairness=False, alpha=0, beta=0, gamma=0, delta=0):\n",
    "    model.to(set_device())\n",
    "    data.to(set_device())\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index)\n",
    "        \n",
    "        if fairness:\n",
    "            loss = fairness_aware_loss(out[data.train_mask], data, data.x[data.train_mask, -1],\n",
    "                                       alpha=alpha, beta=beta, gamma=gamma, delta=delta)\n",
    "            \n",
    "        else:\n",
    "            # criterion = torch.nn.CrossEntropyLoss()\n",
    "            # criterion = torch.nn.BCELoss()\n",
    "            criterion = torch.nn.NLLLoss()\n",
    "            loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        metrics = test(model, data)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch} | Loss: {loss.item()} | \\n AUC_ROC: {metrics[\"AUC_ROC\"]} | F1 Score: {metrics[\"F1_Score\"]} | SPD: {metrics[\"parity\"]} | EOD: {metrics[\"equality\"]}')\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Model Testing\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "# Test the model\n",
    "def test(model, data, balanced=False):\n",
    "    # model.to('cpu')\n",
    "    # data.to('cpu')\n",
    "    model.to(set_device())\n",
    "    data.to(set_device())\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "      out = model(data.x, data.edge_index)\n",
    "\n",
    "    _, pred = model(data.x, data.edge_index).max(dim=1)\n",
    "    correct = int(pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
    "    accuracy = correct / int(data.test_mask.sum())\n",
    "    # print(f'Accuracy: {accuracy}')\n",
    "\n",
    "    # Convert model outputs to binary predictions\n",
    "    predictions = out.argmax(dim=1)\n",
    "\n",
    "    fairness_metrics = calculate_fairness(label='GoodCustomer', predictions=predictions, sens_attr='Gender', balanced=balanced)\n",
    "    fairness_metrics['Accuracy'] = accuracy\n",
    "\n",
    "    return fairness_metrics\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Print Metrics\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "# def print_metrics(metrics):\n",
    "#     for key, value in metrics.items():\n",
    "#         print(f\"\\n{key} : {value:.5f}\")\n",
    "\n",
    "def print_metrics(metrics):\n",
    "    count = -1\n",
    "\n",
    "    for key, value in metrics.items():\n",
    "        count += 1\n",
    "        if count == 3:\n",
    "            print(f\"\\n\\n{key} : {value:.5f}\")\n",
    "            count = 0\n",
    "        else:\n",
    "            print(f\"{key} : {value:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data, val=True, balanced=False):\n",
    "    model.to(set_device())\n",
    "    data.to(set_device())\n",
    "    \n",
    "    if val==True:\n",
    "      mask = data.val_mask\n",
    "    else:\n",
    "      mask = data.test_mask\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data.x, data.edge_index)\n",
    "        predictions = out.argmax(dim=1)\n",
    "\n",
    "    # Compute accuracy\n",
    "    correct = int(predictions[mask].eq(data.y[mask]).sum().item())\n",
    "    accuracy = correct / int(mask.sum())\n",
    "    \n",
    "    # Extract the predictions and the true labels\n",
    "    y_true = data.y[mask].cpu().numpy()\n",
    "    y_pred = predictions[mask].cpu().numpy()\n",
    "    \n",
    "    # Compute F1 score\n",
    "    f1 = f1_score(y_true, y_pred, average='binary')\n",
    "\n",
    "    # Compute AUC-ROC score\n",
    "    y_probs = out[mask][:, 1].cpu().numpy() \n",
    "    auc_roc = roc_auc_score(y_true, y_probs)\n",
    "    \n",
    "    fairness_metrics = fair_metric('I_am_working_in_field', predictions, 'region')\n",
    "    fairness_metrics['Accuracy'] = accuracy\n",
    "    fairness_metrics['F1_Score'] = f1\n",
    "    fairness_metrics['AUC_ROC'] = auc_roc\n",
    "\n",
    "    return fairness_metrics\n",
    "\n",
    "def fair_metric(labels, pred, sens):\n",
    "\t\n",
    "\tlabels = user_labels[labels].values\n",
    "\tsens = user_labels[sens].values\n",
    "\t\n",
    "\tidx_s0 = sens==0\n",
    "\tidx_s1 = sens==1\n",
    "\n",
    "\tidx_s0_y1 = np.bitwise_and(idx_s0, labels==1)\n",
    "\tidx_s1_y1 = np.bitwise_and(idx_s1, labels==1)\n",
    "\n",
    "\tparity = abs(sum(pred[idx_s0])/sum(idx_s0)-sum(pred[idx_s1])/sum(idx_s1))\n",
    "\tequality = abs(sum(pred[idx_s0_y1])/sum(idx_s0_y1)-sum(pred[idx_s1_y1])/sum(idx_s1_y1))\n",
    "    \n",
    "\treturn {\"parity\": parity.item(), \"equality\": equality.item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sens_attribute_tensor = torch.tensor(user_labels['region'].values, dtype=torch.long)\n",
    "sens_attribute_tensor = sens_attribute_tensor.to(set_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "\tdef __init__(self, nfeat, nhid=128, nclass=2, dropout=0):\n",
    "\t\tsuper(GCN, self).__init__()\n",
    "\t\tself.body = GCN_Body(nfeat,nhid,dropout)\n",
    "\t\tself.fc = nn.Linear(nhid, nclass)\n",
    "\n",
    "\t\tfor m in self.modules():\n",
    "\t\t\tself.weights_init(m)\n",
    "\n",
    "\tdef weights_init(self, m):\n",
    "\t\tif isinstance(m, nn.Linear):\n",
    "\t\t\ttorch.nn.init.xavier_uniform_(m.weight.data)\n",
    "\t\t\tif m.bias is not None:\n",
    "\t\t\t\tm.bias.data.fill_(0.0)\n",
    "\n",
    "\tdef forward(self, x, edge_index):\n",
    "\t\tx = self.body(x, edge_index)\n",
    "\t\tx = self.fc(x)\n",
    "\t\treturn F.log_softmax(x, dim=1)\n",
    "\t\t# return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN_Body(nn.Module):\n",
    "\tdef __init__(self, nfeat, nhid, dropout):\n",
    "\t\tsuper(GCN_Body, self).__init__()\n",
    "\t\tself.gc1 = GCNConv(nfeat, nhid)\n",
    "\n",
    "\tdef forward(self, x, edge_index):\n",
    "\t\tx = self.gc1(x, edge_index)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_model = GCN(data.num_node_features, nhid=128, nclass=2)\n",
    "optimizer_gcn_model = torch.optim.Adam(gcn_model.parameters(), lr=1e-4, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss: 13.554031372070312 | \n",
      " AUC_ROC: 0.652967177654472 | F1 Score: 0.23971968795451537 | SPD: 6.508827209472656e-05 | EOD: 0.0\n",
      "Epoch 10 | Loss: 11.339096069335938 | \n",
      " AUC_ROC: 0.6608146930603364 | F1 Score: 0.24003707136237254 | SPD: 2.104043960571289e-05 | EOD: 0.0\n",
      "Epoch 20 | Loss: 9.143600463867188 | \n",
      " AUC_ROC: 0.6643993833865522 | F1 Score: 0.2413471778487753 | SPD: 0.0001608729362487793 | EOD: 0.00016731023788452148\n",
      "Epoch 30 | Loss: 6.980764389038086 | \n",
      " AUC_ROC: 0.6661004273447911 | F1 Score: 0.24447141316073356 | SPD: 0.00494152307510376 | EOD: 0.00012803077697753906\n",
      "Epoch 40 | Loss: 4.879600524902344 | \n",
      " AUC_ROC: 0.663621398805917 | F1 Score: 0.250398171871754 | SPD: 0.020292580127716064 | EOD: 0.0014576315879821777\n",
      "Epoch 50 | Loss: 2.938910484313965 | \n",
      " AUC_ROC: 0.6496008908407831 | F1 Score: 0.2601446067581526 | SPD: 0.03919243812561035 | EOD: 0.011277258396148682\n",
      "Epoch 60 | Loss: 1.4622902870178223 | \n",
      " AUC_ROC: 0.6170459625252376 | F1 Score: 0.26683291770573564 | SPD: 0.04673641920089722 | EOD: 0.05650407075881958\n",
      "Epoch 70 | Loss: 0.7918225526809692 | \n",
      " AUC_ROC: 0.5722226940816628 | F1 Score: 0.2457010582010582 | SPD: 0.014611214399337769 | EOD: 0.02734413743019104\n",
      "Epoch 80 | Loss: 0.6427317261695862 | \n",
      " AUC_ROC: 0.537917636169962 | F1 Score: 0.17137196631996038 | SPD: 0.00649772584438324 | EOD: 0.002692490816116333\n",
      "Epoch 90 | Loss: 0.6304470300674438 | \n",
      " AUC_ROC: 0.5213244125202092 | F1 Score: 0.11866946359005093 | SPD: 0.016507752239704132 | EOD: 0.012808039784431458\n",
      "Epoch 100 | Loss: 0.6313098669052124 | \n",
      " AUC_ROC: 0.5159808641307144 | F1 Score: 0.10387157695939565 | SPD: 0.01718217134475708 | EOD: 0.01631864905357361\n",
      "Epoch 110 | Loss: 0.6283653378486633 | \n",
      " AUC_ROC: 0.5160727528285629 | F1 Score: 0.10430411561420044 | SPD: 0.01736415922641754 | EOD: 0.016131654381752014\n",
      "Epoch 120 | Loss: 0.6236289739608765 | \n",
      " AUC_ROC: 0.5181777042050062 | F1 Score: 0.1112818936366431 | SPD: 0.017802894115447998 | EOD: 0.014558181166648865\n",
      "Epoch 130 | Loss: 0.6191740036010742 | \n",
      " AUC_ROC: 0.5204792139468627 | F1 Score: 0.1190619362597715 | SPD: 0.01700499653816223 | EOD: 0.012906193733215332\n",
      "Epoch 140 | Loss: 0.6153845191001892 | \n",
      " AUC_ROC: 0.522111485257547 | F1 Score: 0.1233038348082596 | SPD: 0.016574367880821228 | EOD: 0.013458862900733948\n",
      "Epoch 150 | Loss: 0.6119446754455566 | \n",
      " AUC_ROC: 0.5229013875529085 | F1 Score: 0.12744811458637825 | SPD: 0.015997491776943207 | EOD: 0.012534216046333313\n",
      "Epoch 160 | Loss: 0.608565628528595 | \n",
      " AUC_ROC: 0.5229554129277134 | F1 Score: 0.1272992700729927 | SPD: 0.015859365463256836 | EOD: 0.013184040784835815\n",
      "Epoch 170 | Loss: 0.6051437854766846 | \n",
      " AUC_ROC: 0.5225518891783938 | F1 Score: 0.12704918032786883 | SPD: 0.016372866928577423 | EOD: 0.012888580560684204\n",
      "Epoch 180 | Loss: 0.6016735434532166 | \n",
      " AUC_ROC: 0.5219078050384645 | F1 Score: 0.1252941176470588 | SPD: 0.01731373369693756 | EOD: 0.014404170215129852\n",
      "Epoch 190 | Loss: 0.5981689095497131 | \n",
      " AUC_ROC: 0.5212250182998068 | F1 Score: 0.12185743862762496 | SPD: 0.01776059716939926 | EOD: 0.015811271965503693\n",
      "Epoch 200 | Loss: 0.5946385860443115 | \n",
      " AUC_ROC: 0.5205748434163355 | F1 Score: 0.1212121212121212 | SPD: 0.01855359971523285 | EOD: 0.016303054988384247\n",
      "Epoch 210 | Loss: 0.5910876989364624 | \n",
      " AUC_ROC: 0.5199777347354577 | F1 Score: 0.1210134128166915 | SPD: 0.018902979791164398 | EOD: 0.01587948203086853\n",
      "Epoch 220 | Loss: 0.5875217914581299 | \n",
      " AUC_ROC: 0.5194301672992967 | F1 Score: 0.11919736448038334 | SPD: 0.018677107989788055 | EOD: 0.01706034690141678\n",
      "Epoch 230 | Loss: 0.5839458703994751 | \n",
      " AUC_ROC: 0.5188894099858363 | F1 Score: 0.11626506024096385 | SPD: 0.018928974866867065 | EOD: 0.01669565588235855\n",
      "Epoch 240 | Loss: 0.5803652405738831 | \n",
      " AUC_ROC: 0.5183549112710552 | F1 Score: 0.11376701966717095 | SPD: 0.019557856023311615 | EOD: 0.01577000319957733\n",
      "Epoch 250 | Loss: 0.5767849683761597 | \n",
      " AUC_ROC: 0.5178274624720276 | F1 Score: 0.11158536585365852 | SPD: 0.019268609583377838 | EOD: 0.014844343066215515\n",
      "Epoch 260 | Loss: 0.5732093453407288 | \n",
      " AUC_ROC: 0.5173000376523051 | F1 Score: 0.11192660550458716 | SPD: 0.019731737673282623 | EOD: 0.015424959361553192\n",
      "Epoch 270 | Loss: 0.5696427822113037 | \n",
      " AUC_ROC: 0.5167630690690798 | F1 Score: 0.11090573012939003 | SPD: 0.020063236355781555 | EOD: 0.016418814659118652\n",
      "Epoch 280 | Loss: 0.5660884976387024 | \n",
      " AUC_ROC: 0.5162387855383496 | F1 Score: 0.10911345319280844 | SPD: 0.020310238003730774 | EOD: 0.017432309687137604\n",
      "Epoch 290 | Loss: 0.5625507831573486 | \n",
      " AUC_ROC: 0.5157092265604569 | F1 Score: 0.1071651090342679 | SPD: 0.020432114601135254 | EOD: 0.01740235835313797\n",
      "Epoch 300 | Loss: 0.5590324401855469 | \n",
      " AUC_ROC: 0.5151983714406858 | F1 Score: 0.10473502665412356 | SPD: 0.020784743130207062 | EOD: 0.01735278218984604\n",
      "Epoch 310 | Loss: 0.5555368065834045 | \n",
      " AUC_ROC: 0.5147051650896036 | F1 Score: 0.10353535353535354 | SPD: 0.020800992846488953 | EOD: 0.0173424631357193\n",
      "Epoch 320 | Loss: 0.5520665049552917 | \n",
      " AUC_ROC: 0.5142236606395003 | F1 Score: 0.10171646535282898 | SPD: 0.021038249135017395 | EOD: 0.017814606428146362\n",
      "Epoch 330 | Loss: 0.5486236810684204 | \n",
      " AUC_ROC: 0.5137923208960511 | F1 Score: 0.09913655260633195 | SPD: 0.02124299854040146 | EOD: 0.017804279923439026\n",
      "Epoch 340 | Loss: 0.5452108979225159 | \n",
      " AUC_ROC: 0.5133785340040696 | F1 Score: 0.09778063686072691 | SPD: 0.021512754261493683 | EOD: 0.02088504284620285\n",
      "Epoch 350 | Loss: 0.5418300628662109 | \n",
      " AUC_ROC: 0.5129587043271567 | F1 Score: 0.09789303079416531 | SPD: 0.021278753876686096 | EOD: 0.02068772166967392\n",
      "Epoch 360 | Loss: 0.5384827256202698 | \n",
      " AUC_ROC: 0.5126093738077789 | F1 Score: 0.0942100098135427 | SPD: 0.02179713547229767 | EOD: 0.018029533326625824\n",
      "Epoch 370 | Loss: 0.5351707935333252 | \n",
      " AUC_ROC: 0.5122773563468161 | F1 Score: 0.09351333552848207 | SPD: 0.022317126393318176 | EOD: 0.017773322761058807\n",
      "Epoch 380 | Loss: 0.5318953990936279 | \n",
      " AUC_ROC: 0.5120063901971065 | F1 Score: 0.08915502328675981 | SPD: 0.023015879094600677 | EOD: 0.019367434084415436\n",
      "Epoch 390 | Loss: 0.5286576151847839 | \n",
      " AUC_ROC: 0.5117377500400095 | F1 Score: 0.08721905400872192 | SPD: 0.0231848806142807 | EOD: 0.021611377596855164\n",
      "Epoch 400 | Loss: 0.5254588723182678 | \n",
      " AUC_ROC: 0.5115222720027272 | F1 Score: 0.08628244017526121 | SPD: 0.02378775179386139 | EOD: 0.021935775876045227\n",
      "Epoch 410 | Loss: 0.5222997665405273 | \n",
      " AUC_ROC: 0.5113270324991044 | F1 Score: 0.08680908782638183 | SPD: 0.023895010352134705 | EOD: 0.021364472806453705\n",
      "Epoch 420 | Loss: 0.5191810131072998 | \n",
      " AUC_ROC: 0.5111766103170577 | F1 Score: 0.08469945355191257 | SPD: 0.02448488026857376 | EOD: 0.023047424852848053\n",
      "Epoch 430 | Loss: 0.5161038041114807 | \n",
      " AUC_ROC: 0.5111081494004719 | F1 Score: 0.0816326530612245 | SPD: 0.02413877099752426 | EOD: 0.02353920042514801\n",
      "Epoch 440 | Loss: 0.5130680799484253 | \n",
      " AUC_ROC: 0.5111018668224874 | F1 Score: 0.07935955447267665 | SPD: 0.02392590045928955 | EOD: 0.02403097227215767\n",
      "Epoch 450 | Loss: 0.51007479429245 | \n",
      " AUC_ROC: 0.5111321526850611 | F1 Score: 0.0759493670886076 | SPD: 0.02372116595506668 | EOD: 0.025881286710500717\n",
      "Epoch 460 | Loss: 0.5071242451667786 | \n",
      " AUC_ROC: 0.5112135624265004 | F1 Score: 0.07454739084132056 | SPD: 0.02372116595506668 | EOD: 0.02532961592078209\n",
      "Epoch 470 | Loss: 0.5042169094085693 | \n",
      " AUC_ROC: 0.5113416598753278 | F1 Score: 0.07229778095919828 | SPD: 0.023774802684783936 | EOD: 0.025260400027036667\n",
      "Epoch 480 | Loss: 0.5013532638549805 | \n",
      " AUC_ROC: 0.5115430141017978 | F1 Score: 0.06933911159263272 | SPD: 0.023420564830303192 | EOD: 0.02523045241832733\n",
      "Epoch 490 | Loss: 0.4985335171222687 | \n",
      " AUC_ROC: 0.5117946289521432 | F1 Score: 0.06707983959168794 | SPD: 0.02278357744216919 | EOD: 0.023694228380918503\n"
     ]
    }
   ],
   "source": [
    "training(model=gcn_model, \n",
    "         data=data, \n",
    "         optimizer=optimizer_gcn_model, \n",
    "         fairness=False,  \n",
    "         epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the values for the GCN model\n",
      "parity : 0.02251\n",
      "equality : 0.02212\n",
      "Accuracy : 0.80907\n",
      "\n",
      "\n",
      "F1_Score : 0.06338\n",
      "AUC_ROC : 0.51208\n"
     ]
    }
   ],
   "source": [
    "print(\"Here are the values for the GCN model\")\n",
    "\n",
    "metrics_gcn_model = test(gcn_model, data)\n",
    "\n",
    "print_metrics(metrics_gcn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FairnessAwareMessagePassingLayer(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(FairnessAwareMessagePassingLayer, self).__init__(aggr='mean')  \n",
    "        self.lin = nn.Linear(in_channels, out_channels)\n",
    "        self.sensitive_attr = sens_attribute_tensor\n",
    "        self.bias_correction = nn.Parameter(torch.rand(1))\n",
    "\n",
    "    def forward(self, x, edge_index):        \n",
    "        # Add self-loops \n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "\n",
    "        x = self.lin(x)\n",
    "\n",
    "        return self.propagate(edge_index, size=(x.size(0), x.size(0)), x=x)\n",
    "    \n",
    "    def message(self, x_j, edge_index, size):\n",
    "        row, col = edge_index\n",
    "        deg = degree(row, size[0], dtype=x_j.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "        \n",
    "        group_difference = self.sensitive_attr[row] - self.sensitive_attr[col]\n",
    "        \n",
    "        # Adjust messages based on statistical parity\n",
    "        fairness_adjustment = (1 + self.bias_correction * group_difference.view(-1, 1))\n",
    "\n",
    "        return fairness_adjustment * norm.view(-1, 1) * x_j\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        return aggr_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FairMP_GCN(torch.nn.Module):\n",
    "    def __init__(self, data, layers=1, hidden=128, dropout=0):\n",
    "        super(FairMP_GCN, self).__init__()\n",
    "        self.conv1 = FairnessAwareMessagePassingLayer(data.num_node_features, hidden)\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        \n",
    "        for i in range(layers - 1):\n",
    "            self.convs.append(FairnessAwareMessagePassingLayer(hidden, hidden))\n",
    "        \n",
    "        # self.conv2 = FairnessAwareMessagePassingLayer(hidden, 2)\n",
    "        self.fc = nn.Linear(hidden, 2)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, edge_index, *args, **kwargs):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        # x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        for conv in self.convs:\n",
    "            x = F.relu(conv(x, edge_index))\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        # x = self.conv2(x, edge_index)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fair_gcn_model = FairMP_GCN(data, hidden=128)\n",
    "optimizer_Fair_gcn_model = torch.optim.Adam(Fair_gcn_model.parameters(), lr=1e-4, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss: 0.6815136075019836 | \n",
      " AUC_ROC: 0.6273797721994774 | F1 Score: 0.1857638888888889 | SPD: 0.03570357710123062 | EOD: 0.03975442051887512\n",
      "Epoch 10 | Loss: 0.6433648467063904 | \n",
      " AUC_ROC: 0.5310808245025146 | F1 Score: 0.0 | SPD: 0.0 | EOD: 0.0\n",
      "Epoch 20 | Loss: 0.6131405830383301 | \n",
      " AUC_ROC: 0.5159950598794426 | F1 Score: 0.0 | SPD: 0.0 | EOD: 0.0\n",
      "Epoch 30 | Loss: 0.5900135636329651 | \n",
      " AUC_ROC: 0.5107287248529625 | F1 Score: 0.0 | SPD: 0.0 | EOD: 0.0\n",
      "Epoch 40 | Loss: 0.572541356086731 | \n",
      " AUC_ROC: 0.5082667456001453 | F1 Score: 0.0 | SPD: 0.0 | EOD: 0.0\n",
      "Epoch 50 | Loss: 0.5593021512031555 | \n",
      " AUC_ROC: 0.506990087386823 | F1 Score: 0.0 | SPD: 0.0 | EOD: 0.0\n",
      "Epoch 60 | Loss: 0.54914790391922 | \n",
      " AUC_ROC: 0.506554119637454 | F1 Score: 0.0 | SPD: 0.0 | EOD: 0.0\n",
      "Epoch 70 | Loss: 0.5412221550941467 | \n",
      " AUC_ROC: 0.5067043739643639 | F1 Score: 0.0 | SPD: 0.0 | EOD: 0.0\n",
      "Epoch 80 | Loss: 0.5349090695381165 | \n",
      " AUC_ROC: 0.5072114643332053 | F1 Score: 0.0 | SPD: 0.0 | EOD: 0.0\n",
      "Epoch 90 | Loss: 0.5297756791114807 | \n",
      " AUC_ROC: 0.507980696467412 | F1 Score: 0.0 | SPD: 0.0 | EOD: 0.0\n",
      "Epoch 100 | Loss: 0.5255128145217896 | \n",
      " AUC_ROC: 0.5089585725368949 | F1 Score: 0.0 | SPD: 0.0 | EOD: 0.0\n",
      "Epoch 110 | Loss: 0.521902322769165 | \n",
      " AUC_ROC: 0.5101605831728678 | F1 Score: 0.0 | SPD: 0.0 | EOD: 0.0\n",
      "Epoch 120 | Loss: 0.518792450428009 | \n",
      " AUC_ROC: 0.5115121527358972 | F1 Score: 0.0 | SPD: 0.0 | EOD: 0.0\n",
      "Epoch 130 | Loss: 0.5160808563232422 | \n",
      " AUC_ROC: 0.5129681042148281 | F1 Score: 0.0 | SPD: 0.0 | EOD: 0.0\n",
      "Epoch 140 | Loss: 0.513691782951355 | \n",
      " AUC_ROC: 0.5145097817101494 | F1 Score: 0.0 | SPD: 0.0 | EOD: 0.0\n",
      "Epoch 150 | Loss: 0.5115430355072021 | \n",
      " AUC_ROC: 0.5161347633120273 | F1 Score: 0.0 | SPD: 0.0 | EOD: 0.0\n",
      "Epoch 160 | Loss: 0.509550929069519 | \n",
      " AUC_ROC: 0.5178935494373904 | F1 Score: 0.0 | SPD: 0.0 | EOD: 0.0\n",
      "Epoch 170 | Loss: 0.5076825022697449 | \n",
      " AUC_ROC: 0.5196702001451899 | F1 Score: 0.0 | SPD: 0.0 | EOD: 0.0\n",
      "Epoch 180 | Loss: 0.5059025287628174 | \n",
      " AUC_ROC: 0.5215459573217284 | F1 Score: 0.0 | SPD: 0.0 | EOD: 0.0\n",
      "Epoch 190 | Loss: 0.5041816830635071 | \n",
      " AUC_ROC: 0.5234572758080032 | F1 Score: 0.0 | SPD: 0.0 | EOD: 0.0\n",
      "Epoch 200 | Loss: 0.5025002956390381 | \n",
      " AUC_ROC: 0.5254235069033782 | F1 Score: 0.0 | SPD: 0.0 | EOD: 0.0\n",
      "Epoch 210 | Loss: 0.5008487701416016 | \n",
      " AUC_ROC: 0.5274089454222859 | F1 Score: 0.0 | SPD: 0.0 | EOD: 0.0\n",
      "Epoch 220 | Loss: 0.4992154836654663 | \n",
      " AUC_ROC: 0.5294435415170258 | F1 Score: 0.0 | SPD: 0.0 | EOD: 0.0\n",
      "Epoch 230 | Loss: 0.4975893199443817 | \n",
      " AUC_ROC: 0.5315118764943004 | F1 Score: 0.0 | SPD: 0.0 | EOD: 0.0\n",
      "Epoch 240 | Loss: 0.49595412611961365 | \n",
      " AUC_ROC: 0.5336192737598826 | F1 Score: 0.0 | SPD: 0.0 | EOD: 0.0\n",
      "Epoch 250 | Loss: 0.49429768323898315 | \n",
      " AUC_ROC: 0.5357898804741936 | F1 Score: 0.0 | SPD: 0.0 | EOD: 0.0\n",
      "Epoch 260 | Loss: 0.4926464855670929 | \n",
      " AUC_ROC: 0.538004081565511 | F1 Score: 0.0 | SPD: 0.0 | EOD: 0.0\n",
      "Epoch 270 | Loss: 0.49101102352142334 | \n",
      " AUC_ROC: 0.540232598302083 | F1 Score: 0.0 | SPD: 0.0 | EOD: 0.0\n",
      "Epoch 280 | Loss: 0.48939114809036255 | \n",
      " AUC_ROC: 0.5424738240704554 | F1 Score: 0.0 | SPD: 0.0 | EOD: 0.0\n",
      "Epoch 290 | Loss: 0.48778897523880005 | \n",
      " AUC_ROC: 0.5447094147020861 | F1 Score: 0.0 | SPD: 0.0 | EOD: 0.0\n",
      "Epoch 300 | Loss: 0.48620182275772095 | \n",
      " AUC_ROC: 0.5469218653041177 | F1 Score: 0.0 | SPD: 0.0 | EOD: 0.0\n",
      "Epoch 310 | Loss: 0.4846194088459015 | \n",
      " AUC_ROC: 0.5491034785195541 | F1 Score: 0.0 | SPD: 0.0 | EOD: 0.0\n",
      "Epoch 320 | Loss: 0.48302167654037476 | \n",
      " AUC_ROC: 0.5513099822538754 | F1 Score: 0.0 | SPD: 0.0 | EOD: 0.0\n",
      "Epoch 330 | Loss: 0.48142650723457336 | \n",
      " AUC_ROC: 0.5535669624258194 | F1 Score: 0.0 | SPD: 0.0 | EOD: 0.0\n",
      "Epoch 340 | Loss: 0.4798479974269867 | \n",
      " AUC_ROC: 0.5559940278101432 | F1 Score: 0.0 | SPD: 0.0 | EOD: 0.0\n",
      "Epoch 350 | Loss: 0.47828006744384766 | \n",
      " AUC_ROC: 0.5584802741199079 | F1 Score: 0.0 | SPD: 0.0 | EOD: 0.0\n",
      "Epoch 360 | Loss: 0.4767235219478607 | \n",
      " AUC_ROC: 0.5609294244443983 | F1 Score: 0.0 | SPD: 0.0 | EOD: 0.0\n",
      "Epoch 370 | Loss: 0.475184828042984 | \n",
      " AUC_ROC: 0.5632614358625762 | F1 Score: 0.0 | SPD: 0.0 | EOD: 0.0\n",
      "Epoch 380 | Loss: 0.4736413359642029 | \n",
      " AUC_ROC: 0.5654251365369654 | F1 Score: 0.0 | SPD: 0.0 | EOD: 0.0\n",
      "Epoch 390 | Loss: 0.4720887541770935 | \n",
      " AUC_ROC: 0.5676848503497118 | F1 Score: 0.0 | SPD: 2.11246770049911e-05 | EOD: 0.0\n",
      "Epoch 400 | Loss: 0.4705653190612793 | \n",
      " AUC_ROC: 0.5702158660224419 | F1 Score: 0.0 | SPD: 4.22493540099822e-05 | EOD: 0.0\n",
      "Epoch 410 | Loss: 0.4690791368484497 | \n",
      " AUC_ROC: 0.5727914352443896 | F1 Score: 0.0 | SPD: 4.22493540099822e-05 | EOD: 0.0\n",
      "Epoch 420 | Loss: 0.46764442324638367 | \n",
      " AUC_ROC: 0.5752901987515127 | F1 Score: 0.0 | SPD: 4.22493540099822e-05 | EOD: 0.0\n",
      "Epoch 430 | Loss: 0.46627089381217957 | \n",
      " AUC_ROC: 0.5776541026457183 | F1 Score: 0.0 | SPD: 4.22493540099822e-05 | EOD: 0.0\n",
      "Epoch 440 | Loss: 0.46494919061660767 | \n",
      " AUC_ROC: 0.5799188521125743 | F1 Score: 0.0 | SPD: 4.22493540099822e-05 | EOD: 0.0\n",
      "Epoch 450 | Loss: 0.46367231011390686 | \n",
      " AUC_ROC: 0.5820025338452307 | F1 Score: 0.0 | SPD: 1.1374650057405233e-05 | EOD: 0.0\n",
      "Epoch 460 | Loss: 0.4624340534210205 | \n",
      " AUC_ROC: 0.5840051655260271 | F1 Score: 0.0011019283746556475 | SPD: 5.3624011343345046e-05 | EOD: 0.00033472804352641106\n",
      "Epoch 470 | Loss: 0.46122825145721436 | \n",
      " AUC_ROC: 0.5860133124470387 | F1 Score: 0.0022026431718061676 | SPD: 7.474867743439972e-05 | EOD: 0.0005020920652896166\n",
      "Epoch 480 | Loss: 0.460051029920578 | \n",
      " AUC_ROC: 0.5878880624927553 | F1 Score: 0.0022026431718061676 | SPD: 9.587335807736963e-05 | EOD: 0.0006694560870528221\n",
      "Epoch 490 | Loss: 0.458899587392807 | \n",
      " AUC_ROC: 0.5896242601125405 | F1 Score: 0.0022026431718061676 | SPD: 6.499866140075028e-05 | EOD: 0.0003150974807795137\n"
     ]
    }
   ],
   "source": [
    "training(model=Fair_gcn_model, \n",
    "         data=data, \n",
    "         optimizer=optimizer_Fair_gcn_model, \n",
    "         fairness=False,  \n",
    "         epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the values for the GCN model\n",
      "parity : 0.00006\n",
      "equality : 0.00032\n",
      "Accuracy : 0.86390\n",
      "\n",
      "\n",
      "F1_Score : 0.00220\n",
      "AUC_ROC : 0.59110\n"
     ]
    }
   ],
   "source": [
    "print(\"Here are the values for the GCN model\")\n",
    "\n",
    "metrics_Fair_gcn_model = test(Fair_gcn_model, data)\n",
    "\n",
    "print_metrics(metrics_Fair_gcn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A-FAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch.nn import Linear, Parameter\n",
    "from torch_geometric.utils import add_self_loops, softmax\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Attention_FairMessagePassing(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Attention_FairMessagePassing, self).__init__(aggr='add') \n",
    "        self.lin = Linear(in_channels, out_channels) \n",
    "        self.att = Linear(2 * out_channels, 1) \n",
    "        \n",
    "        self.sensitive_attr = sens_attribute_tensor \n",
    "        self.bias_correction = Parameter(torch.rand(1))  \n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "\n",
    "        x = self.lin(x)\n",
    "\n",
    "        return self.propagate(edge_index, size=(x.size(0), x.size(0)), x=x)\n",
    "\n",
    "    def message(self, edge_index, x_i, x_j, size_i):\n",
    "        x_cat = torch.cat([x_i, x_j], dim=-1)  \n",
    "        alpha = self.att(x_cat)\n",
    "\n",
    "        row, col = edge_index\n",
    "        group_difference = self.sensitive_attr[row] - self.sensitive_attr[col]\n",
    "\n",
    "        fairness_adjustment = self.bias_correction * group_difference.view(-1, 1)\n",
    "        alpha = alpha + fairness_adjustment\n",
    "\n",
    "        alpha = softmax(alpha, edge_index[0], num_nodes=size_i)\n",
    "\n",
    "        return alpha * x_j\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        return aggr_out\n",
    "    \n",
    "# GCN class that takes in the data as an input for dimensions of the convolutions\n",
    "class Fair_Attention_MP_GCN(torch.nn.Module):\n",
    "    def __init__(self, data, layers=1, hidden=128, dropout=0):\n",
    "        super(Fair_Attention_MP_GCN, self).__init__()\n",
    "        self.conv1 = Attention_FairMessagePassing(data.num_node_features, hidden)\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        \n",
    "        for i in range(layers - 1):\n",
    "            self.convs.append(Attention_FairMessagePassing(hidden, hidden))\n",
    "        \n",
    "        # self.conv2 = Attention_FairMessagePassing(hidden, 2)\n",
    "        self.fc = Linear(hidden, 2)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, edge_index, *args, **kwargs):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        # x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        for conv in self.convs:\n",
    "            x = F.relu(conv(x, edge_index))\n",
    "            # x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        # x = self.conv2(x, edge_index)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss: 1.584642767906189 | \n",
      " AUC_ROC: 0.5931573709530906 | F1 Score: 0.23970384081443777 | SPD: 5.960464477539063e-08 | EOD: 0.0\n",
      "Epoch 10 | Loss: 1.2166472673416138 | \n",
      " AUC_ROC: 0.5974106762485413 | F1 Score: 0.23970384081443777 | SPD: 4.225969314575195e-05 | EOD: 0.0\n",
      "Epoch 20 | Loss: 0.9129007458686829 | \n",
      " AUC_ROC: 0.502815002585209 | F1 Score: 0.23419800254708756 | SPD: 0.003240227699279785 | EOD: 0.013856947422027588\n",
      "Epoch 30 | Loss: 0.7247875928878784 | \n",
      " AUC_ROC: 0.300975171203847 | F1 Score: 0.10556511761331039 | SPD: 0.029507756233215332 | EOD: 0.008954018354415894\n",
      "Epoch 40 | Loss: 0.6505813002586365 | \n",
      " AUC_ROC: 0.2965778941594709 | F1 Score: 0.029992107340173643 | SPD: 0.034958869218826294 | EOD: 0.0007502324879169464\n",
      "Epoch 50 | Loss: 0.6096094250679016 | \n",
      " AUC_ROC: 0.3297947711973822 | F1 Score: 0.010359712230215827 | SPD: 0.019068658351898193 | EOD: 0.002813221886754036\n",
      "Epoch 60 | Loss: 0.5719518065452576 | \n",
      " AUC_ROC: 0.38146055838306203 | F1 Score: 0.007012076353720295 | SPD: 0.006007328629493713 | EOD: 0.002459871117025614\n",
      "Epoch 70 | Loss: 0.5375492572784424 | \n",
      " AUC_ROC: 0.44361146465932383 | F1 Score: 0.0055274067250115156 | SPD: 0.0006401371210813522 | EOD: 0.0022139851935207844\n",
      "Epoch 80 | Loss: 0.5110507011413574 | \n",
      " AUC_ROC: 0.5014069617582355 | F1 Score: 0.009896091044037604 | SPD: 0.00017218850553035736 | EOD: 0.003749202936887741\n",
      "Epoch 90 | Loss: 0.4928677976131439 | \n",
      " AUC_ROC: 0.5447789546874099 | F1 Score: 0.014314928425357875 | SPD: 0.000988030806183815 | EOD: 0.003295682370662689\n",
      "Epoch 100 | Loss: 0.4806376099586487 | \n",
      " AUC_ROC: 0.5737405841061424 | F1 Score: 0.026571282575370468 | SPD: 0.0018118927255272865 | EOD: 0.005450775846838951\n",
      "Epoch 110 | Loss: 0.47207286953926086 | \n",
      " AUC_ROC: 0.5925033354014685 | F1 Score: 0.03363914373088685 | SPD: 0.0030631273984909058 | EOD: 0.00609959289431572\n",
      "Epoch 120 | Loss: 0.4656672179698944 | \n",
      " AUC_ROC: 0.6049923810553322 | F1 Score: 0.03762074224707676 | SPD: 0.0029331305995583534 | EOD: 0.005252452567219734\n",
      "Epoch 130 | Loss: 0.460542768239975 | \n",
      " AUC_ROC: 0.6138091879393879 | F1 Score: 0.03869653767820774 | SPD: 0.0028015058487653732 | EOD: 0.005478709936141968\n",
      "Epoch 140 | Loss: 0.4562237560749054 | \n",
      " AUC_ROC: 0.6205615205143197 | F1 Score: 0.040774719673802244 | SPD: 0.003098876215517521 | EOD: 0.005330976098775864\n",
      "Epoch 150 | Loss: 0.4524048864841461 | \n",
      " AUC_ROC: 0.6261926047534753 | F1 Score: 0.04085801838610827 | SPD: 0.0033409977331757545 | EOD: 0.0062266867607831955\n",
      "Epoch 160 | Loss: 0.4488808512687683 | \n",
      " AUC_ROC: 0.6311424609088166 | F1 Score: 0.04285714285714286 | SPD: 0.0031849993392825127 | EOD: 0.00874646008014679\n",
      "Epoch 170 | Loss: 0.44554972648620605 | \n",
      " AUC_ROC: 0.6355338390440928 | F1 Score: 0.04290091930541368 | SPD: 0.0034384960308670998 | EOD: 0.009435545653104782\n",
      "Epoch 180 | Loss: 0.4423646330833435 | \n",
      " AUC_ROC: 0.6394716965785321 | F1 Score: 0.04200819672131148 | SPD: 0.0036107422783970833 | EOD: 0.009770272299647331\n",
      "Epoch 190 | Loss: 0.43930333852767944 | \n",
      " AUC_ROC: 0.6430398651634073 | F1 Score: 0.04200819672131148 | SPD: 0.0034043695777654648 | EOD: 0.009081188589334488\n",
      "Epoch 200 | Loss: 0.43635445833206177 | \n",
      " AUC_ROC: 0.6463041679917232 | F1 Score: 0.04207285787583376 | SPD: 0.003545740619301796 | EOD: 0.009415915235877037\n",
      "Epoch 210 | Loss: 0.4335063695907593 | \n",
      " AUC_ROC: 0.6494290791184228 | F1 Score: 0.04108885464817668 | SPD: 0.0035278666764497757 | EOD: 0.009770272299647331\n",
      "Epoch 220 | Loss: 0.4307626187801361 | \n",
      " AUC_ROC: 0.6524926511822061 | F1 Score: 0.03913491246138002 | SPD: 0.003669237717986107 | EOD: 0.010085372254252434\n",
      "Epoch 230 | Loss: 0.42812681198120117 | \n",
      " AUC_ROC: 0.6555083365733372 | F1 Score: 0.03816400206291903 | SPD: 0.0036416128277778625 | EOD: 0.009189661592245102\n",
      "Epoch 240 | Loss: 0.42560169100761414 | \n",
      " AUC_ROC: 0.658518698558695 | F1 Score: 0.03715170278637771 | SPD: 0.0038317348808050156 | EOD: 0.0095243901014328\n",
      "Epoch 250 | Loss: 0.42318400740623474 | \n",
      " AUC_ROC: 0.661486928904669 | F1 Score: 0.03619441571871768 | SPD: 0.0037732338532805443 | EOD: 0.0096917524933815\n",
      "Epoch 260 | Loss: 0.4208795726299286 | \n",
      " AUC_ROC: 0.6644259284775016 | F1 Score: 0.037209302325581395 | SPD: 0.003678985871374607 | EOD: 0.009022297337651253\n",
      "Epoch 270 | Loss: 0.4186933934688568 | \n",
      " AUC_ROC: 0.6673051236629559 | F1 Score: 0.03724780134505949 | SPD: 0.003734234720468521 | EOD: 0.00883530080318451\n",
      "Epoch 280 | Loss: 0.4166317284107208 | \n",
      " AUC_ROC: 0.670142427002079 | F1 Score: 0.03626943005181347 | SPD: 0.0035798605531454086 | EOD: 0.008126582950353622\n",
      "Epoch 290 | Loss: 0.41467806696891785 | \n",
      " AUC_ROC: 0.6729242901873853 | F1 Score: 0.036288232244686365 | SPD: 0.0038934824988245964 | EOD: 0.009357025846838951\n",
      "Epoch 300 | Loss: 0.4128095805644989 | \n",
      " AUC_ROC: 0.6755779839859485 | F1 Score: 0.03632589517384535 | SPD: 0.0037699826061725616 | EOD: 0.00989837571978569\n",
      "Epoch 310 | Loss: 0.4110109806060791 | \n",
      " AUC_ROC: 0.6781244183519761 | F1 Score: 0.03630705394190871 | SPD: 0.003812232054769993 | EOD: 0.010420100763440132\n",
      "Epoch 320 | Loss: 0.4092719554901123 | \n",
      " AUC_ROC: 0.6805596606794019 | F1 Score: 0.03734439834024896 | SPD: 0.0038024820387363434 | EOD: 0.010252736508846283\n",
      "Epoch 330 | Loss: 0.40758848190307617 | \n",
      " AUC_ROC: 0.6829441627968464 | F1 Score: 0.0374025974025974 | SPD: 0.0035538598895072937 | EOD: 0.009711382910609245\n",
      "Epoch 340 | Loss: 0.4059564173221588 | \n",
      " AUC_ROC: 0.6852428909392899 | F1 Score: 0.037422037422037424 | SPD: 0.0035538598895072937 | EOD: 0.009396282956004143\n",
      "Epoch 350 | Loss: 0.40437009930610657 | \n",
      " AUC_ROC: 0.6875452399568315 | F1 Score: 0.037460978147762745 | SPD: 0.003440110944211483 | EOD: 0.009750643745064735\n",
      "Epoch 360 | Loss: 0.4028254449367523 | \n",
      " AUC_ROC: 0.689781238236652 | F1 Score: 0.036420395421436005 | SPD: 0.0036497339606285095 | EOD: 0.010085372254252434\n",
      "Epoch 370 | Loss: 0.4013157784938812 | \n",
      " AUC_ROC: 0.6919882695156895 | F1 Score: 0.036420395421436005 | SPD: 0.00363998394459486 | EOD: 0.010291997343301773\n",
      "Epoch 380 | Loss: 0.3998435139656067 | \n",
      " AUC_ROC: 0.6941146583910567 | F1 Score: 0.0374414976599064 | SPD: 0.003514859825372696 | EOD: 0.009957268834114075\n",
      "Epoch 390 | Loss: 0.39840731024742126 | \n",
      " AUC_ROC: 0.6962409513492027 | F1 Score: 0.03846153846153846 | SPD: 0.003420610912144184 | EOD: 0.009100817143917084\n",
      "Epoch 400 | Loss: 0.3970041275024414 | \n",
      " AUC_ROC: 0.6983382533272605 | F1 Score: 0.03846153846153846 | SPD: 0.0032646125182509422 | EOD: 0.00857909582555294\n",
      "Epoch 410 | Loss: 0.3956313729286194 | \n",
      " AUC_ROC: 0.70039349560385 | F1 Score: 0.038481539261570455 | SPD: 0.003171989694237709 | EOD: 0.007870377972722054\n",
      "Epoch 420 | Loss: 0.3942876160144806 | \n",
      " AUC_ROC: 0.7023882380932078 | F1 Score: 0.03954214360041624 | SPD: 0.003046865575015545 | EOD: 0.007200922816991806\n",
      "Epoch 430 | Loss: 0.3929699659347534 | \n",
      " AUC_ROC: 0.704359864532272 | F1 Score: 0.03854166666666666 | SPD: 0.0027234945446252823 | EOD: 0.0075552798807621\n",
      "Epoch 440 | Loss: 0.39167770743370056 | \n",
      " AUC_ROC: 0.7062885680148776 | F1 Score: 0.03856175091193329 | SPD: 0.002544746734201908 | EOD: 0.007220551371574402\n",
      "Epoch 450 | Loss: 0.3904103636741638 | \n",
      " AUC_ROC: 0.7081862662557509 | F1 Score: 0.039603960396039604 | SPD: 0.0026487456634640694 | EOD: 0.0077619049698114395\n",
      "Epoch 460 | Loss: 0.3891682028770447 | \n",
      " AUC_ROC: 0.7100550214751464 | F1 Score: 0.040625 | SPD: 0.00258537195622921 | EOD: 0.007427176460623741\n",
      "Epoch 470 | Loss: 0.3879507780075073 | \n",
      " AUC_ROC: 0.7118803741519779 | F1 Score: 0.044675324675324674 | SPD: 0.0024586236104369164 | EOD: 0.006944717839360237\n",
      "Epoch 480 | Loss: 0.3867575228214264 | \n",
      " AUC_ROC: 0.7137089160764121 | F1 Score: 0.04561949196474857 | SPD: 0.0025512482970952988 | EOD: 0.007318703457713127\n",
      "Epoch 490 | Loss: 0.3855854272842407 | \n",
      " AUC_ROC: 0.7154331240435554 | F1 Score: 0.04566683964711987 | SPD: 0.002393624745309353 | EOD: 0.00664924830198288\n"
     ]
    }
   ],
   "source": [
    "Fair_gat_model = Fair_Attention_MP_GCN(data, hidden=128)\n",
    "optimizer_Fair_gat_model = torch.optim.Adam(Fair_gat_model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "training(model=Fair_gat_model, \n",
    "         data=data, \n",
    "         optimizer=optimizer_Fair_gat_model, \n",
    "         fairness=False,  \n",
    "         epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the values for the FairGAT model\n",
      "parity : 0.00256\n",
      "equality : 0.00700\n",
      "Accuracy : 0.86172\n",
      "\n",
      "\n",
      "F1_Score : 0.04463\n",
      "AUC_ROC : 0.71695\n"
     ]
    }
   ],
   "source": [
    "print(\"Here are the values for the FairGAT model\")\n",
    "\n",
    "metrics_Fair_gat_model = test(Fair_gat_model, data)\n",
    "\n",
    "print_metrics(metrics_Fair_gat_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(nn.Module):\n",
    "\tdef __init__(self, nfeat, nhid=128, nclass=2, dropout=0):\n",
    "\t\tsuper(GAT, self).__init__()\n",
    "\t\tself.body = GAT_Body(nfeat,nhid,dropout)\n",
    "\t\tself.fc = nn.Linear(nhid, nclass)\n",
    "\n",
    "\t\tfor m in self.modules():\n",
    "\t\t\tself.weights_init(m)\n",
    "\n",
    "\tdef weights_init(self, m):\n",
    "\t\tif isinstance(m, nn.Linear):\n",
    "\t\t\ttorch.nn.init.xavier_uniform_(m.weight.data)\n",
    "\t\t\tif m.bias is not None:\n",
    "\t\t\t\tm.bias.data.fill_(0.0)\n",
    "\n",
    "\tdef forward(self, x, edge_index):\n",
    "\t\tx = self.body(x, edge_index)\n",
    "\t\tx = self.fc(x)\n",
    "\t\treturn F.log_softmax(x, dim=1)\n",
    "\t\t# return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATConv\n",
    "\n",
    "class GAT_Body(nn.Module):\n",
    "\tdef __init__(self, nfeat, nhid, dropout):\n",
    "\t\tsuper(GAT_Body, self).__init__()\n",
    "\t\tself.gc1 = GATConv(nfeat, nhid)\n",
    "\n",
    "\tdef forward(self, x, edge_index):\n",
    "\t\tx = self.gc1(x, edge_index)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss: 0.5074151158332825 | \n",
      " AUC_ROC: 0.5081963663391366 | F1 Score: 0.005083884087442806 | SPD: 0.0041469912976026535 | EOD: 0.0022253128699958324\n",
      "Epoch 10 | Loss: 0.43689197301864624 | \n",
      " AUC_ROC: 0.5644506175702221 | F1 Score: 0.0643298969072165 | SPD: 0.0006485432386398315 | EOD: 0.01597733050584793\n",
      "Epoch 20 | Loss: 0.4275059103965759 | \n",
      " AUC_ROC: 0.5346444370193858 | F1 Score: 0.01772525849335303 | SPD: 0.0007426794618368149 | EOD: 1.761317253112793e-05\n",
      "Epoch 30 | Loss: 0.42103058099746704 | \n",
      " AUC_ROC: 0.5552340037291656 | F1 Score: 0.040268456375838924 | SPD: 0.008134722709655762 | EOD: 0.00903160497546196\n",
      "Epoch 40 | Loss: 0.41611284017562866 | \n",
      " AUC_ROC: 0.5464979831246118 | F1 Score: 0.023711340206185563 | SPD: 2.271495759487152e-05 | EOD: 0.0030983686447143555\n",
      "Epoch 50 | Loss: 0.4119758903980255 | \n",
      " AUC_ROC: 0.5610691758355937 | F1 Score: 0.035478966041561075 | SPD: 0.0020718947052955627 | EOD: 0.007388925179839134\n",
      "Epoch 60 | Loss: 0.4082701802253723 | \n",
      " AUC_ROC: 0.5635351836116987 | F1 Score: 0.03298969072164949 | SPD: 0.0015145167708396912 | EOD: 0.006542792543768883\n",
      "Epoch 70 | Loss: 0.4048514664173126 | \n",
      " AUC_ROC: 0.5707970284653058 | F1 Score: 0.032938754503345345 | SPD: 0.0018362626433372498 | EOD: 0.0071234069764614105\n",
      "Epoch 80 | Loss: 0.4016415774822235 | \n",
      " AUC_ROC: 0.5771995269554487 | F1 Score: 0.03604531410916581 | SPD: 0.0022100061178207397 | EOD: 0.007182300090789795\n",
      "Epoch 90 | Loss: 0.39859914779663086 | \n",
      " AUC_ROC: 0.5825825213021357 | F1 Score: 0.03925619834710744 | SPD: 0.002010132186114788 | EOD: 0.006365111097693443\n",
      "Epoch 100 | Loss: 0.39571624994277954 | \n",
      " AUC_ROC: 0.5897015454134711 | F1 Score: 0.04338842975206611 | SPD: 0.002156379632651806 | EOD: 0.005754545331001282\n",
      "Epoch 110 | Loss: 0.39299583435058594 | \n",
      " AUC_ROC: 0.5964404735567491 | F1 Score: 0.04455958549222798 | SPD: 0.0018330086022615433 | EOD: 0.005833068862557411\n",
      "Epoch 120 | Loss: 0.3904271125793457 | \n",
      " AUC_ROC: 0.6027267683334857 | F1 Score: 0.04465212876427831 | SPD: 0.0015990110114216805 | EOD: 0.005980802699923515\n",
      "Epoch 130 | Loss: 0.3879969120025635 | \n",
      " AUC_ROC: 0.6089474077723547 | F1 Score: 0.041601664066562655 | SPD: 0.00166238471865654 | EOD: 0.007211240008473396\n",
      "Epoch 140 | Loss: 0.38568753004074097 | \n",
      " AUC_ROC: 0.6149788265132272 | F1 Score: 0.043591074208614425 | SPD: 0.0015470115467905998 | EOD: 0.006728779524564743\n",
      "Epoch 150 | Loss: 0.38347312808036804 | \n",
      " AUC_ROC: 0.6207029744361903 | F1 Score: 0.042509072058061176 | SPD: 0.0012350156903266907 | EOD: 0.006020061671733856\n",
      "Epoch 160 | Loss: 0.38131824135780334 | \n",
      " AUC_ROC: 0.6261896552989253 | F1 Score: 0.044605809128630707 | SPD: 0.0016315095126628876 | EOD: 0.006039692088961601\n",
      "Epoch 170 | Loss: 0.3791763186454773 | \n",
      " AUC_ROC: 0.6313521599335256 | F1 Score: 0.04462895692786716 | SPD: 0.0013195136561989784 | EOD: 0.003972433507442474\n",
      "Epoch 180 | Loss: 0.37702128291130066 | \n",
      " AUC_ROC: 0.6361512821758516 | F1 Score: 0.04462895692786716 | SPD: 0.0011310167610645294 | EOD: 0.003972433507442474\n",
      "Epoch 190 | Loss: 0.374955415725708 | \n",
      " AUC_ROC: 0.6406285302033498 | F1 Score: 0.04559585492227979 | SPD: 0.0006695222109556198 | EOD: 0.0029682498425245285\n",
      "Epoch 200 | Loss: 0.3731931447982788 | \n",
      " AUC_ROC: 0.6448473292784968 | F1 Score: 0.04655975168132437 | SPD: 0.0005184011533856392 | EOD: 0.002672780305147171\n",
      "Epoch 210 | Loss: 0.3717402219772339 | \n",
      " AUC_ROC: 0.6485129018014357 | F1 Score: 0.04449042938437662 | SPD: 2.278294414281845e-05 | EOD: 0.0006055217236280441\n",
      "Epoch 220 | Loss: 0.3704479932785034 | \n",
      " AUC_ROC: 0.6520314811829835 | F1 Score: 0.044398554465668566 | SPD: 0.0002876557409763336 | EOD: 0.0018948540091514587\n",
      "Epoch 230 | Loss: 0.3692414164543152 | \n",
      " AUC_ROC: 0.6555061544565564 | F1 Score: 0.04538421866941723 | SPD: 0.0003266558051109314 | EOD: 0.0023081041872501373\n",
      "Epoch 240 | Loss: 0.3681093752384186 | \n",
      " AUC_ROC: 0.6587795934001854 | F1 Score: 0.047373841400617914 | SPD: 0.0003981553018093109 | EOD: 0.003912532702088356\n",
      "Epoch 250 | Loss: 0.36704787611961365 | \n",
      " AUC_ROC: 0.6618399762163659 | F1 Score: 0.04732510288065843 | SPD: 0.00016415957361459732 | EOD: 0.0031149722635746002\n",
      "Epoch 260 | Loss: 0.36604923009872437 | \n",
      " AUC_ROC: 0.6646303520550481 | F1 Score: 0.050308008213552365 | SPD: 0.00012841075658798218 | EOD: 0.0030261315405368805\n",
      "Epoch 270 | Loss: 0.3651065230369568 | \n",
      " AUC_ROC: 0.6672437126621233 | F1 Score: 0.05330599692465403 | SPD: 4.228763282299042e-05 | EOD: 0.0020415782928466797\n",
      "Epoch 280 | Loss: 0.364214152097702 | \n",
      " AUC_ROC: 0.6696674928816233 | F1 Score: 0.05319693094629156 | SPD: 3.091245889663696e-05 | EOD: 0.002228572964668274\n",
      "Epoch 290 | Loss: 0.3633679151535034 | \n",
      " AUC_ROC: 0.6719663888792038 | F1 Score: 0.05515832482124617 | SPD: 2.4335458874702454e-05 | EOD: 0.0024548284709453583\n",
      "Epoch 300 | Loss: 0.3625640869140625 | \n",
      " AUC_ROC: 0.6741228717827026 | F1 Score: 0.05615109749872384 | SPD: 0.00012028776109218597 | EOD: 0.0032028071582317352\n",
      "Epoch 310 | Loss: 0.3617994785308838 | \n",
      " AUC_ROC: 0.6761371334265616 | F1 Score: 0.05711371749107598 | SPD: 0.0001479126513004303 | EOD: 0.0031139664351940155\n",
      "Epoch 320 | Loss: 0.3610711395740509 | \n",
      " AUC_ROC: 0.6780105406311823 | F1 Score: 0.058133605303416616 | SPD: 0.00019828788936138153 | EOD: 0.0036749467253684998\n",
      "Epoch 330 | Loss: 0.3603765666484833 | \n",
      " AUC_ROC: 0.6797752496449504 | F1 Score: 0.059063136456211814 | SPD: 6.3333660364151e-05 | EOD: 0.002483770251274109\n",
      "Epoch 340 | Loss: 0.35971370339393616 | \n",
      " AUC_ROC: 0.6814764134997158 | F1 Score: 0.06297613001523615 | SPD: 4.0665268898010254e-05 | EOD: 0.0026903972029685974\n",
      "Epoch 350 | Loss: 0.359080046415329 | \n",
      " AUC_ROC: 0.6830275628206243 | F1 Score: 0.06389452332657201 | SPD: 0.0004485342651605606 | EOD: 0.00337948277592659\n",
      "Epoch 360 | Loss: 0.35847389698028564 | \n",
      " AUC_ROC: 0.6845058390327746 | F1 Score: 0.06582278481012657 | SPD: 0.0003006616607308388 | EOD: 0.002375297248363495\n",
      "Epoch 370 | Loss: 0.35789334774017334 | \n",
      " AUC_ROC: 0.6858859199897867 | F1 Score: 0.06585612968591692 | SPD: 0.00036241114139556885 | EOD: 0.0025819242000579834\n",
      "Epoch 380 | Loss: 0.35733669996261597 | \n",
      " AUC_ROC: 0.6871741841868663 | F1 Score: 0.06582278481012657 | SPD: 0.0004225363954901695 | EOD: 0.003142908215522766\n",
      "Epoch 390 | Loss: 0.3568023145198822 | \n",
      " AUC_ROC: 0.688367993900432 | F1 Score: 0.06771096513390601 | SPD: 0.0006711585447192192 | EOD: 0.0035168975591659546\n",
      "Epoch 400 | Loss: 0.3562884032726288 | \n",
      " AUC_ROC: 0.6895316376479506 | F1 Score: 0.06663301362948006 | SPD: 0.0006987843662500381 | EOD: 0.003910515457391739\n",
      "Epoch 410 | Loss: 0.35579395294189453 | \n",
      " AUC_ROC: 0.6906437498684137 | F1 Score: 0.06464646464646465 | SPD: 0.0005509108304977417 | EOD: 0.0035757869482040405\n",
      "Epoch 420 | Loss: 0.35531747341156006 | \n",
      " AUC_ROC: 0.6916613836260576 | F1 Score: 0.06666666666666667 | SPD: 0.0003607887774705887 | EOD: 0.003428056836128235\n",
      "Epoch 430 | Loss: 0.35485726594924927 | \n",
      " AUC_ROC: 0.6926081105779766 | F1 Score: 0.06750629722921914 | SPD: 0.00015929248183965683 | EOD: 0.00225650891661644\n",
      "Epoch 440 | Loss: 0.35441121459007263 | \n",
      " AUC_ROC: 0.6935155114692297 | F1 Score: 0.06653225806451613 | SPD: 3.0829571187496185e-05 | EOD: 0.001587051898241043\n",
      "Epoch 450 | Loss: 0.3539768159389496 | \n",
      " AUC_ROC: 0.6943823873345529 | F1 Score: 0.06656580937972768 | SPD: 0.00026004109531641006 | EOD: 0.0017936751246452332\n",
      "Epoch 460 | Loss: 0.35355067253112793 | \n",
      " AUC_ROC: 0.6952593345080954 | F1 Score: 0.06545820745216516 | SPD: 0.00014141947031021118 | EOD: 0.00254165381193161\n",
      "Epoch 470 | Loss: 0.3531262278556824 | \n",
      " AUC_ROC: 0.6961405260186733 | F1 Score: 0.06542526421741318 | SPD: 7.80448317527771e-05 | EOD: 0.002226557582616806\n",
      "Epoch 480 | Loss: 0.3526928424835205 | \n",
      " AUC_ROC: 0.6970503727990655 | F1 Score: 0.06539235412474849 | SPD: 0.00010892003774642944 | EOD: 0.0010157488286495209\n",
      "Epoch 490 | Loss: 0.35211220383644104 | \n",
      " AUC_ROC: 0.6986630290380276 | F1 Score: 0.06532663316582915 | SPD: 0.00012842006981372833 | EOD: 0.001222372055053711\n"
     ]
    }
   ],
   "source": [
    "gat_model = GAT(data.num_node_features, nhid=128)\n",
    "optimizer_gat_model = torch.optim.Adam(gat_model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "training(model=gat_model, \n",
    "         data=data, \n",
    "         optimizer=optimizer_gat_model, \n",
    "         fairness=False,  \n",
    "         epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the values for the GAT model\n",
      "parity : 0.00040\n",
      "equality : 0.00014\n",
      "Accuracy : 0.86060\n",
      "\n",
      "\n",
      "F1_Score : 0.06734\n",
      "AUC_ROC : 0.70169\n"
     ]
    }
   ],
   "source": [
    "print(\"Here are the values for the GAT model\")\n",
    "\n",
    "metrics_gat_model = test(gat_model, data)\n",
    "\n",
    "print_metrics(metrics_gat_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN model: {'parity': 0.02251383662223816, 'equality': 0.022118743509054184, 'Accuracy': 0.8090731560763107, 'F1_Score': 0.06337509211495947, 'AUC_ROC': 0.5120805581883501}\n",
      "\n",
      "Fair GCN model: {'parity': 5.5248645367100835e-05, 'equality': 0.0003150974807795137, 'Accuracy': 0.8639026588553402, 'F1_Score': 0.0022026431718061676, 'AUC_ROC': 0.591099586870141}\n",
      "\n",
      "GAT model: {'parity': 0.0004045739769935608, 'equality': 0.00013617053627967834, 'Accuracy': 0.8605978669070151, 'F1_Score': 0.06733668341708542, 'AUC_ROC': 0.7016853806760275}\n",
      "\n",
      "Fair GAT model: {'parity': 0.002559373155236244, 'equality': 0.007003609091043472, 'Accuracy': 0.8617245005257623, 'F1_Score': 0.04462895692786716, 'AUC_ROC': 0.7169496232683286}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"GCN model: {metrics_gcn_model}\\n\")\n",
    "print(f\"Fair GCN model: {metrics_Fair_gcn_model}\\n\")\n",
    "print(f\"GAT model: {metrics_gat_model}\\n\")\n",
    "print(f\"Fair GAT model: {metrics_Fair_gat_model}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Values for the FairGAT model - same model specifications as the one from Carlos,\n",
    "but with one A-FAME instead of one GCNConv layer\n",
    "\n",
    "parity : 0.00706\n",
    "equality : 0.00207\n",
    "Accuracy : 0.68000\n",
    "F1_Score : 0.80952\n",
    "AUC_ROC : 0.67496"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
